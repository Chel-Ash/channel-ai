<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-07-25T12:04:35+01:00</updated><id>http://localhost:4000/feed.xml</id><entry><title type="html">How to Build an Object Detection Model using Transfer Learning in Keras</title><link href="http://localhost:4000/object-detection-model-in-keras-with-mask-R-CNN/" rel="alternate" type="text/html" title="How to Build an Object Detection Model using Transfer Learning in Keras" /><published>2020-07-24T00:00:00+01:00</published><updated>2020-07-24T00:00:00+01:00</updated><id>http://localhost:4000/object%20detection%20model%20in%20keras%20with%20mask%20R-CNN</id><content type="html" xml:base="http://localhost:4000/object-detection-model-in-keras-with-mask-R-CNN/">&lt;p&gt;In this tutorial you would see how to apply state-of-the-art R-CNN architecture model built on the MS Coco dataset for Object Detection on a new Dataset. We use Transfer Learning for efficient and faster training epochs. You would learn how to Install the R-CNN Library, install the dataset we want to make predictions on, parse the annotation files for bounding boxes, Train Mask R-CNN Model on dataset using Transfer Learning.&lt;/p&gt;

&lt;h3&gt;Overview&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Gentle introduction to Object Detection&lt;/li&gt;
  &lt;li&gt;Object Detection task in Computer Vision using Mask R-CNN&lt;/li&gt;
  &lt;li&gt;Preparing R-CNN library Model&lt;/li&gt;
  &lt;li&gt;Installing the Dataset (Kangaroo)&lt;/li&gt;
  &lt;li&gt;Training Mask R-CNN Model on Dataset using Transfer Learning&lt;/li&gt;
  &lt;li&gt;Detecting Kangaroo in new Images.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that you have an idea of the steps taking us through this tutorial, Let’s begin with it.&lt;/p&gt;

&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Object Detection is a Computer Vision task that involves identifying the presence, location, and class of one or more objects in an image. It is a challenging problem that involves building upon methods for Object recognition (e.g. where are they), object localization (e.g. what are their extent), and object classification (e.g. what are they).&lt;/p&gt;

&lt;p&gt;In this tutorial, we are going to use the Region based Convolutional Neural network (R-CNN) to perform object Detection and idetify kangaroos in images. This pre-built model can be used on other datasets to identify other classes of images. For now, we look at a single class (i.e kangaroo) of image.&lt;/p&gt;

&lt;p&gt;We want our model to predict the objects in unseen images and draw a bounding box around them. As we implement this simple task using a simgle class of image, we can get a better understanding of this task and later move on to larger classes of images like in the Coco Dataset.&lt;/p&gt;

&lt;p&gt;Here, instead of developing an implementation of the R-CNN or Mask R-CNN model from scratch, we can use a reliable third-party implementation built on top of the Keras deep learning framework. The best-of-breed third-party implementations of Mask R-CNN is the Mask R-CNN Project developed by Matterport. The project is open source released under a permissive license (e.g. MIT license) and the code has been widely used on a variety of projects and Kaggle competitions. Let’s Begin.&lt;/p&gt;

&lt;p&gt;For this tutorial, some libraries used are not avvailable in tensorflow 2x, please use 1x for this tutorial. Ro change the version you arerunning in colab, use the code below. If you are following this guide on your machine you can create a virtual and install tensorflow 1x.&lt;/p&gt;

&lt;h3&gt;Install Tensorflow 1x&lt;/h3&gt;
&lt;pre class=&quot;css&quot;&gt;&lt;code&gt;
#%tensorflow_version 1.x
#import tensorflow as tf
print(tf.__version__)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Installing the R-CNN library&lt;/h3&gt;
&lt;p&gt;This involves:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cloning github repo&lt;/li&gt;
  &lt;li&gt;Running the installation script&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To git clone in Colab like I am doing, use the code below. If you are doing this locally on your machine, write the code without the exclamation mark “git clone https://github.com/matterport/Mask_RCNN.git”&lt;/p&gt;

&lt;pre class=&quot;css&quot;&gt;&lt;code&gt;
	!git clone https://github.com/matterport/Mask_RCNN.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After running the above,, a new directory “Mask_RCNN” should appear in the files section on colab. And like-wise, a local-directory should be created on your machine. It comes with the following folders:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;assets&lt;/li&gt;
  &lt;li&gt;images&lt;/li&gt;
  &lt;li&gt;samples&lt;/li&gt;
  &lt;li&gt;mrcnn etc..
Next, we can install the library by moving into Mask_RCNN directory and running the code below.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you are using Google Colab for this guide,, to change directory use the last two lines in the code below,, otherwise use the first two after uncommenting them.&lt;/p&gt;

&lt;pre class=&quot;css&quot;&gt;&lt;code&gt;
#cd /content/Mask_RCNN/
#python setup.py install
%cd /content/Mask_RCNN
!python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After running this, the success messages confirms that you installed the library successfully and that you have the latest version, which at the time of writing is version 2.1.&lt;/p&gt;

&lt;p&gt;To be sure, we can confirm the library installed properly using the code below.&lt;/p&gt;

&lt;pre class=&quot;css&quot;&gt;&lt;code&gt;
#Use first line if your are implementing on a local machine, other wise use the second line
#pip show mask-rcnn
!pip show mask-rcnn
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Preparing dataset for Object detection&lt;/h3&gt;
&lt;p&gt;Next, we would start to work with the dataset. We are using the Kangaroo dataset by Huynh Ngoc Anh. It consists of 183 photographs that contain kangaroos, and XML annotation files that provide bounding boxes for the kangaroos in each photograph. We would use mask-rcnn model to perform object detection on the dataset. The R-CNN library is built to perform both object detection tasks and masking, but the kangoroo datatset does not provide mask so we would be focusing on the object detection task here.&lt;/p&gt;

&lt;p&gt;In the next few sections, we look at how to prepare the dataset by downloading, parsing annotations and developing a KangarooDataset object that can be used by Mask_RCNN library.&lt;/p&gt;

&lt;h3&gt;Installing the Dataset&lt;/h3&gt;
&lt;p&gt;Follow the code below to download the kangaroo dataset by cloning it directly from the github repo. A kangaroo directory is created with two sub-directories images and annotes which contain JPEG photos of kangaroos and XML files describing the locations of their bounding boxes respectively.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
#git clone https://github.com/experiencor/kangaroo.git
!git clone https://github.com/experiencor/kangaroo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Parsing Annotation File&lt;/h3&gt;
&lt;p&gt;Next, we can parse the annots subdirectory containing the size and locations of each object in pictures from the dataset. We can use Python ElementTree API to get fast results. ElementTree API can be used to load and parse an XML file and we can use the find() and findall() functions to perform the XPath queries on a loaded document.&lt;/p&gt;

&lt;p&gt;Let’s understand how this would work by looking at a file from annots. Open up the first file “00001.xml”. On Colab, you can download the file and open it with Sublime text or any other text-editor. It looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\assets\images\Blog\Blog-img\Kangaroo_Dataset_XML_file_1.webp.png&quot; class=&quot;img-fluid&quot; alt=&quot;Annotation_File_Showing_Bounding_Box_position_In_Kangaroo_Dataset&quot; width=&quot;100%&quot; height=&quot;60vh&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that it has a size, two objects and two bndbox elements. This is what would define ;&lt;/p&gt;

&lt;p&gt;The size of the image
The number of objects in a photo
The bounding box location of each object.
First, the annotation file must be loaded and parsed as an ElementTree object. Use the code below to do that.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
from xml.etree import ElementTree
import os
# load and parse the file
path = '/content/Mask_RCNN/kangaroo/annots'
for filename in os.listdir(path):
    if not filename.endswith('.xml'): continue
fullname = os.path.join(path, filename)
tree = ElementTree.parse(fullname)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once loaded, we can retrieve the root element of the document from which we can perform our XPath queries.&lt;/p&gt;

&lt;pre class=&quot;css&quot;&gt;&lt;code&gt;
# get the root of the document
root = tree.getroot()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can use the findall() function with a query for ‘.//bndbox‘ to find all ‘bndbox‘ elements, then enumerate each to extract the x and y, min and max values that define each bounding box.&lt;/p&gt;

&lt;p&gt;The element text can also be parsed to integer values.&lt;/p&gt;

&lt;p&gt;We can then collect the definition of each bounding box into a list (coors)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
	# extract each bounding box
	for box in root.findall('.//bndbox'):
	xmin = int(box.find('xmin').text)
	ymin = int(box.find('ymin').text)
	xmax = int(box.find('xmax').text)
	ymax = int(box.find('ymax').text)
	coors = [xmin, ymin, xmax, ymax]
	print(coors
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Image Dimensions may also be needed, we can query that directly&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# extract image dimensions
width = int(root.find('.//size/width').text)
height = int(root.find('.//size/height').text)
print(width,height)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For ease of use, we can define a function that that takes all the process above and implements it in the steps below when it is called.&lt;/p&gt;

&lt;p&gt;Get annotation filename as an argument
Extract the bounding box using the xmin, ymin, xmax, ymax values.
Extract the image dimension details from the width &amp;amp; height values.
Return them for use
The function extract_all() in the code cell below implements this behaviour.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
	def extract_all(filename):
	# load and parse the file
	tree = ElementTree.parse(filename)
	# get the root of the document
	root = tree.getroot()
	# extract each bounding box
	boxes = list()
	for box in root.findall('.//bndbox'):
	xmin = int(box.find('xmin').text)
	ymin = int(box.find('ymin').text)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can test out this function on our annotation files. Let’s pick the first file for this test.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# extract details form annotation file
boxes, w, h = extract_all('kangaroo/annots/00001.xml')
# summarize extracted details
print(boxes, w, h)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Developing Kangaroo Dataset Object
The mask-rcnn library requires that train, validation, and test datasets be called by a mrcnn.utils.Dataset object. This means that a new class must be defined that extends the mrcnn.utils.Dataset class and defines a function to load the dataset, with any name you like such as load_dataset(), and override two functions, one for loading a mask called load_mask() and one for loading an image reference (path or URL) called image_reference().&lt;/p&gt;

&lt;h1 id=&quot;class-that-defines-and-loads-the-kangaroo-dataset&quot;&gt;class that defines and loads the kangaroo dataset&lt;/h1&gt;
&lt;p&gt;To use a Dataset object, it is instantiated, then your custom load function must be called, then finally the built-in prepare() function is called.&lt;/p&gt;

&lt;p&gt;Let’s do that in the code cell below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# prepare the dataset
#train_set = KangarooDataset()
#train_set.load_dataset(...)
#train_set.prepare()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The custom load function, e.g. load_dataset() is responsible for both defining the classes and for defining the images in the dataset.&lt;/p&gt;

&lt;p&gt;Classes are defined by calling the built-in add_class() function and specifying the ‘source‘ (the name of the dataset), the ‘class_id‘ or integer for the class (e.g. 1 for the first class as 0 is reserved for the background class), and the ‘class_name‘ (e.g. ‘kangaroo‘).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# define one class
#self.add_class(&quot;dataset&quot;, 1, &quot;kangaroo&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Objects are defined by a call to the built-in add_image() function and specifying the ‘source‘ (the name of the dataset), a unique ‘image_id‘ (e.g. the filename without the file extension like ‘00001‘), and the path for where the image can be loaded (e.g. ‘kangaroo/images/00001.jpg‘).&lt;/p&gt;

&lt;p&gt;This will define an “image info” dictionary for the image that can be retrieved later via the index or order in which the image was added to the dataset. You can also specify other arguments that will be added to the image info dictionary, such as an ‘annotation‘ to define the annotation path.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# define one image
# add to dataset
#self.add_image('dataset', image_id='00001', path='kangaroo/images/00001.jpg', annotation='kangaroo/annots/00001.xml')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we can implement a load_dataset() function that takes the path to dataset directory and loads all image in it. Image with number ‘00090‘ has an issue, so it would be excluded when we write code to load all images. We can also devide the dataset when loading into training and validation sets. The full photos are about 160. In a 80/20 ratio, we are left with about 131 photos in the training set and 20 in validation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
	# load the dataset definitions
	def load_dataset(self, dataset_dir, is_train=True):
	# define one class
	self.add_class(&quot;dataset&quot;, 1, &quot;kangaroo&quot;)
	# define data locations
	images_dir = dataset_dir + '/images/'
	annotations_dir = dataset_dir + '/annots/'
	# find all images
	for filename in listdir(images_dir):
		# extract image id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we need to define the load_mask() function for loading the mask for a given ‘image_id‘. Here, we use load_mask() function to call an image with its id. The id here is the integer value assigned to all images when loading them from the dataset. They are arranged in incresing order. The id of the image corresponds to that of our annotation, therefore we substitute loading masks which we don’t have for xml files describing bounding boxes for an image.&lt;/p&gt;

&lt;p&gt;To retrieve the annotation on each files we must specify the path to the files, then we can use the function extract_all we defined earlier to get the x,y points in an image describing the bounding boxes and dimensions. Note: self.image_info is a built-in function&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# get details of image
#info = self.image_info[image_id]
# define box file location
#path = info['annotation']
# load XML
#boxes, w, h = self.extract_boxes(path)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now define a mask value for the images. A mask is a two-dimensional array with the same dimensions as the photograph with all zero values where the object isn’t and one values where the object is.&lt;/p&gt;

&lt;p&gt;We can achieve this by creating a NumPy array with all zero values for the known size of the image and one channel for each bounding box.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
import numpy as np
# create one array for all masks, each on a different channel
masks = zeros([h, w, len(boxes)], dtype='uint8')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each bounding box is defined as min and max, x and y coordinates of the box.&lt;/p&gt;

&lt;p&gt;These can be used directly to define row and column ranges in the array that can then be marked as 1.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# create masks
#for i in range(len(boxes)):
#	box = boxes[i]
#	row_s, row_e = box[1], box[3]
#	col_s, col_e = box[0], box[2]
#	masks[row_s:row_e, col_s:col_e, i] = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All objects have the same class in this dataset. We can retrieve the class index via the ‘class_names‘ dictionary, then add it to a list to be returned alongside the masks.&lt;/p&gt;

&lt;p&gt;#self.class_names.index(‘kangaroo’)
Putting all this together,, we have a load_dataset() function that looks like below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
	# load the masks for an image
	def load_mask(self, image_id):
	# get details of image
	info = self.image_info[image_id]
	# define box file location
	path = info['annotation']
	# load XML
	boxes, w, h = self.extract_boxes(path)
	# create one array for all masks, each on a different channel
	masks = zeros([h, w, len(boxes)], dtype='uint8')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we must implement the image_reference() function.&lt;/p&gt;

&lt;p&gt;This function is responsible for returning the path or URL for a given ‘image_id’.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
	# load an image reference
	def image_reference(self, image_id):
	info = self.image_info[image_id]
	return info['path']
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that’s it. We have successfully defined a Dataset object for the mask-rcnn library for our Kangaroo dataset.&lt;/p&gt;

&lt;p&gt;The complete code for loading our dataset, defining the path for object bounding boxes, creating a mask for images and so on is below&lt;/p&gt;

&lt;h1 id=&quot;split-into-train-and-test-set&quot;&gt;split into train and test set&lt;/h1&gt;
&lt;p&gt;from os import listdir
from xml.etree import ElementTree
from numpy import zeros
from numpy import asarray
from mrcnn.utils import Dataset&lt;/p&gt;

&lt;h1 id=&quot;class-that-defines-and-loads-the-kangaroo-dataset-1&quot;&gt;class that defines and loads the kangaroo dataset&lt;/h1&gt;
&lt;p&gt;class KangarooDataset(Dataset):
	# load the dataset definitions&lt;/p&gt;

&lt;p&gt;Now that we have defined the dataset, let’s confirm that the images, masks, and bounding boxes are handled correctly&lt;/p&gt;

&lt;p&gt;Testing KangarooDataset Object
Now we are gonna confirm that this works properly. We are gonna load an image by specifying an image_id and calling it with the load_image function and likewise, the mask of the image by calling load_mask function with the same image_id. Let’s do that in the code cell below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# load an image
image_id = 1
image = train_set.load_image(image_id)
print(image.shape)
# load image mask
mask, class_ids = train_set.load_mask(image_id)
print(mask.shape)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we can plot the photograph using the Matplotlib Library. We can then plot the mask over the image, we specify an alpha value for the mask here so that it remains transparent and we can still see the image underneath.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
from matplotlib import pyplot
#plot the image
pyplot.imshow(image)
# plot mask
pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)
pyplot.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The complete code for the example is listed below&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;h1 id=&quot;plot-one-photograph-and-mask&quot;&gt;plot one photograph and mask&lt;/h1&gt;
&lt;p&gt;from os import listdir
from xml.etree import ElementTree
from numpy import zeros
from numpy import asarray
from mrcnn.utils import Dataset
from matplotlib import pyplot&lt;/p&gt;

&lt;h1 id=&quot;class-that-defines-and-loads-the-kangaroo-dataset-2&quot;&gt;class that defines and loads the kangaroo dataset&lt;/h1&gt;
&lt;p&gt;class KangarooDataset(Dataset):
&amp;lt;/b&amp;gt;&lt;/p&gt;

&lt;p&gt;Running the example first prints the shape of the photograph and then the masks.&lt;/p&gt;

&lt;p&gt;We can confirm that both arrays have the same width and height and only differ in terms of the number of channels. We can also see that the first photograph (e.g. image_id=0) in this case only has one mask.&lt;/p&gt;

&lt;p&gt;A plot of the photograph is also created with the first mask overlaid.&lt;/p&gt;

&lt;p&gt;In this case, we can see that one kangaroo is present in the photo and that the mask correctly bounds the kangaroo.&lt;/p&gt;

&lt;p&gt;We could repeat this for the first nine photos in the dataset, plotting each photo in one figure as a subplot and plotting all masks for each photo.&lt;/p&gt;

&lt;h1 id=&quot;plot-first-few-images&quot;&gt;plot first few images&lt;/h1&gt;
&lt;p&gt;for i in range(9):
	# define subplot
	pyplot.subplot(330 + 1 + i)
	# plot raw pixel data
	image = train_set.load_image(i)
	pyplot.imshow(image)
	# plot all masks
	mask, _ = train_set.load_mask(i)
	for j in range(mask.shape[2]):&lt;/p&gt;

&lt;p&gt;Running this plots 9 images with the masks of each placed correctly. Also images with multiple kangaroo objects have separate mask defined.&lt;/p&gt;

&lt;p&gt;Finally, the mask-rcnn library provides utilities for displaying images and masks. We can use some of these built-in functions to confirm that the Dataset is operating correctly.&lt;/p&gt;

&lt;p&gt;For example, the mask-rcnn library provides the mrcnn.visualize.display_instances() function that will show a photograph with bounding boxes, masks, and class labels. This requires that the bounding boxes are extracted from the masks via the extract_bboxes() function.&lt;/p&gt;

&lt;h1 id=&quot;display-image-with-masks-and-bounding-boxes&quot;&gt;display image with masks and bounding boxes&lt;/h1&gt;
&lt;p&gt;from os import listdir
from xml.etree import ElementTree
from numpy import zeros
from numpy import asarray
from mrcnn.utils import Dataset
from mrcnn.visualize import display_instances
from mrcnn.utils import extract_bboxes&lt;/p&gt;

&lt;h1 id=&quot;class-that-defines-and-loads-the-kangaroo-dataset-3&quot;&gt;class that defines and loads the kangaroo dataset&lt;/h1&gt;

&lt;p&gt;Running the example creates a plot showing the photograph with the mask for each object in a separate color.&lt;/p&gt;

&lt;p&gt;The bounding boxes match the masks exactly, by design, and are shown with dotted outlines. Finally, each object is marked with the class label, which in this case is ‘kangaroo‘.&lt;/p&gt;

&lt;p&gt;Training Mask RCNN Model on kangaroo Dataset Using Transfer Learning
We can fit/train a new model using the RCNN architecture from scratch to make predictions on new dataset but that would just be a waste of time. Time can be saved and performance improved by using Transfer Learning.&lt;/p&gt;

&lt;p&gt;The first step to using tranfer learning is to download the weights of our pre-fit in our case RCNN. This can be found in the github project.&lt;/p&gt;

&lt;p&gt;Download here Download Weights (mask_rcnn_coco.h5) 246M&lt;/p&gt;

&lt;p&gt;To download directly to colab without having to upload to colab from your sysatem use the code cell below:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Next we must define a configuration object that extends the mrcnn.config.Config class. It should take in properties for the prediction problem like name and number of class and the algorithm for training like the learning rate.&lt;/p&gt;

&lt;p&gt;The configuration must define the name of the configuration via the ‘NAME‘ attribute, e.g. ‘kangaroo_cfg‘, that will be used to save details and models to file during the run. The number of classes in the prediction problem must also be defined via the ‘NUM_CLASSES‘ attribute. In this case, we have only one object type of kangaroo,although there is always an additional class for the background.&lt;/p&gt;

&lt;p&gt;Lastly, the number of samples which is the number of training examples or images must be defined, 132 in this case.&lt;/p&gt;

&lt;p&gt;Now after adding the required, our custom KangarooConfig file would look like this:&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;fit-a-mask-rcnn-on-the-kangaroo-dataset&quot;&gt;fit a mask rcnn on the kangaroo dataset&lt;/h1&gt;
&lt;p&gt;from os import listdir
from xml.etree import ElementTree
from numpy import zeros
from numpy import asarray
from mrcnn.utils import Dataset
from mrcnn.config import Config
from mrcnn.model import MaskRCNN&lt;/p&gt;

&lt;h1 id=&quot;class-that-defines-and-loads-the-kangaroo-dataset-4&quot;&gt;class that defines and loads the kangaroo dataset&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;
	
    #define a configuration for the model
    class KangarooConfig(Config):
	# Give the configuration a recognizable name
	NAME = &quot;kangaroo_cfg&quot;
	# Number of classes (background + kangaroo)
	NUM_CLASSES = 1 + 1
	# Number of training steps per epoch
	STEPS_PER_EPOCH = 131
 
# prepare config
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we would define our model, this is achieved by creating an instance of the mrcnn.model.MaskRCNN class and specifying the model will be used for training via setting the ‘mode‘ argument to ‘training‘. We would also create an instance of our KangarooConfig file in the config parameter. A directory would then be pointed to where configuration files can be saved and for saving checkpoints of the model at the end of each epochs. the current working directory can be used. Let’s do that now:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;h1 id=&quot;define-the-model&quot;&gt;define the model&lt;/h1&gt;
&lt;p&gt;model = MaskRCNN(mode=’training’, model_dir=’./’, config=config)
&amp;lt;/b&amp;gt;
Before we proceed to loading the model weights, we can define a new variable that would hold the fuction we created earlier that loads the training and test test. We would need this data later when we finally start training. The code below shows how to do this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# prepare train set
train_set = KangarooDataset()
train_set.load_dataset('kangaroo', is_train=True)
train_set.prepare()
print('Train: %d' % len(train_set.image_ids))
# prepare test/val set
test_set = KangarooDataset()
test_set.load_dataset('kangaroo', is_train=False)
test_set.prepare()
print('Test: %d' % len(test_set.image_ids))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, the pre-define model weights can be loaded, we specify a path to the saved weights “mask_rcnn_coco.h5”, we call the load_weights function on model defined above.&lt;/p&gt;

&lt;p&gt;The model will be used as it is, although the class-specific output layers will be removed so that new output layers can be defined and trained. This can be done by specifying the ‘exclude‘ argument and listing all of the output layers to exclude or remove from the model after it is loaded. This includes the output layers for the classification label, bounding boxes, and masks.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# load weights (mscoco)
model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[&quot;mrcnn_class_logits&quot;, &quot;mrcnn_bbox_fc&quot;,  &quot;mrcnn_bbox&quot;, &quot;mrcnn_mask&quot;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, the model can be fit on the training dataset by calling the train() function and passing in both the training dataset and the validation dataset. We can also specify the learning rate as the default learning rate in the configuration (0.001).&lt;/p&gt;

&lt;p&gt;We can also specify what layers to train. In this case, we will only train the heads, that is the output layers of the model.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;train-weights-output-layers-or-heads&quot;&gt;train weights (output layers or ‘heads’)&lt;/h1&gt;
&lt;p&gt;model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers=’heads’)
We could train this for more epochs that fine-tune all of the weights in the model. This could also be achieved by using a smaller learning rate and changing the ‘layer’ argument from ‘heads’ to ‘all’.&lt;/p&gt;

&lt;p&gt;Running this training step can take a bit of time to execute on a modern CPU, if you are running on colab, you can switch to a GPU by clicking the Runtime and selecting change runtime.&lt;/p&gt;

&lt;p&gt;We can see that there are many different train and test loss scores reported for each of the output heads of the network. It can be quite confusing as to which loss to pay attention to.&lt;/p&gt;

&lt;p&gt;In this example where we are interested in object detection instead of object segmentation, I recommend paying attention to the loss for the classification output on the train and validation datasets (e.g. mrcnn_class_loss and val_mrcnn_class_loss), as well as the loss for the bounding box output for the train and validation datasets (mrcnn_bbox_loss and val_mrcnn_bbox_loss).&lt;/p&gt;

&lt;p&gt;A model file is created and saved at the end of each epoch in a subdirectory that starts with ‘kangaroo_cfg‘ followed by random characters.&lt;/p&gt;

&lt;p&gt;A model must be selected for use; in this case, the loss continues to decrease for the bounding boxes on each epoch, so we will use the final model at the end of the run (‘mask_rcnn_kangaroo_cfg_0005.h5‘).&lt;/p&gt;

&lt;p&gt;Copy the model file from the config directory into your current working directory. We will use it in the following sections to evaluate the model and make predictions.&lt;/p&gt;

&lt;p&gt;The results suggest that perhaps more training epochs could be useful, perhaps fine-tuning all of the layers in the model.&lt;/p&gt;

&lt;p&gt;Next, let’s look at evaluating the performance of this model.&lt;/p&gt;

&lt;p&gt;Evaluating a Mask R-CNN Model
The performance of a model for an object recognition task is often evaluated using the mean absolute precision, or mAP.&lt;/p&gt;

&lt;p&gt;We are predicting bounding boxes so we can determine whether a bounding box prediction is good or not based on how well the predicted and actual bounding boxes overlap. This can be calculated by dividing the area of the overlap by the total area of both bounding boxes, or the intersection divided by the union, referred to as “intersection over union,” or IoU. A perfect bounding box prediction will have an IoU of 1.&lt;/p&gt;

&lt;p&gt;It is standard to assume a positive prediction of a bounding box if the IoU is greater than 0.5, e.g. they overlap by 50% or more.&lt;/p&gt;

&lt;p&gt;Precision refers to the percentage of the correctly predicted bounding boxes (IoU &amp;gt; 0.5) out of all bounding boxes predicted. Recall is the percentage of the correctly predicted bounding boxes (IoU &amp;gt; 0.5) out of all objects in the photo.&lt;/p&gt;

&lt;p&gt;As we make more predictions, the recall percentage will increase, but precision will drop or become erratic as we start making false positive predictions. The recall (x) can be plotted against the precision (y) for each number of predictions to create a curve or line. We can maximize the value of each point on this line and calculate the average value of the precision or AP for each value of recall.&lt;/p&gt;

&lt;p&gt;Note: there are variations on how AP is calculated, e.g. the way it is calculated for the widely used PASCAL VOC dataset and the MS COCO dataset differ.&lt;/p&gt;

&lt;p&gt;The average or mean of the average precision (AP) across all of the images in a dataset is called the mean average precision, or mAP.&lt;/p&gt;

&lt;p&gt;The mask-rcnn library provides a mrcnn.utils.compute_ap to calculate the AP and other metrics for a given images. These AP scores can be collected across a dataset and the mean calculated to give an idea at how good the model is at detecting objects in a dataset.&lt;/p&gt;

&lt;p&gt;First, we must define a new Config object to use for making predictions, instead of training. We can extend our previously defined KangarooConfig to reuse the parameters. Instead, we will define a new object with the same values to keep the code compact. The config must change some of the defaults around using the GPU for inference that are different from how they are set for training a model (regardless of whether you are running on the GPU or CPU).&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;

&lt;h1 id=&quot;define-the-prediction-configuration&quot;&gt;define the prediction configuration&lt;/h1&gt;
&lt;p&gt;class PredictionConfig(Config):
	# define the name of the configuration
	NAME = “kangaroo_cfg”
	# number of classes (background + kangaroo)
	NUM_CLASSES = 1 + 1
	# simplify GPU config
	GPU_COUNT = 1
	IMAGES_PER_GPU = 1
Next, we can define the model with the config and set the ‘mode‘ argument to ‘inference‘ instead of ‘training‘.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;create-config&quot;&gt;create config&lt;/h1&gt;
&lt;p&gt;cfg = PredictionConfig()&lt;/p&gt;
&lt;h1 id=&quot;define-the-model-1&quot;&gt;define the model&lt;/h1&gt;
&lt;p&gt;model = MaskRCNN(mode=’inference’, model_dir=’./’, config=cfg)
Next, we can load the weights from our saved model.&lt;/p&gt;

&lt;p&gt;We can do that by specifying the path to the model file. In this case, the model file is ‘mask_rcnn_kangaroo_cfg_0005.h5‘ in the current working directory.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;load-model-weights&quot;&gt;load model weights&lt;/h1&gt;
&lt;p&gt;model.load_weights(‘mask_rcnn_kangaroo_cfg_0005.h5’, by_name=True)
Next, we can evaluate the model. This involves enumerating the images in a dataset, making a prediction, and calculating the AP for the prediction before predicting a mean AP across all images.&lt;/p&gt;

&lt;p&gt;First, the image and ground truth mask can be loaded from the dataset for a given image_id. This can be achieved using the load_image_gt() convenience function.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;load-image-bounding-boxes-and-masks-for-the-image-id&quot;&gt;load image, bounding boxes and masks for the image id&lt;/h1&gt;
&lt;p&gt;image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)
Next, the pixel values of the loaded image must be scaled in the same way as was performed on the training data, e.g. centered. This can be achieved using the mold_image() convenience function.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;convert-pixel-values-eg-center&quot;&gt;convert pixel values (e.g. center)&lt;/h1&gt;
&lt;p&gt;scaled_image = mold_image(image, cfg)
The dimensions of the image then need to be expanded one sample in a dataset and used as input to make a prediction with the model.&lt;/p&gt;

&lt;p&gt;[ ]
sample = expand_dims(scaled_image, 0)&lt;/p&gt;
&lt;h1 id=&quot;make-prediction&quot;&gt;make prediction&lt;/h1&gt;
&lt;p&gt;yhat = model.detect(sample, verbose=0)&lt;/p&gt;
&lt;h1 id=&quot;extract-results-for-first-sample&quot;&gt;extract results for first sample&lt;/h1&gt;
&lt;p&gt;r = yhat[0]
Next, the prediction can be compared to the ground truth and metrics calculated using the compute_ap() function.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;
&lt;h1 id=&quot;calculate-statistics-including-ap&quot;&gt;calculate statistics, including AP&lt;/h1&gt;
&lt;p&gt;AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[“rois”], r[“class_ids”], r[“scores”], r[‘masks’])&lt;/p&gt;

&lt;p&gt;The AP Values can be added to a list, then the mean value calculated.&lt;/p&gt;

&lt;p&gt;Tying this together, the evaluate_model() function below implements this and calculates the mAP when given a dataset, model and configuration.&lt;/p&gt;

&lt;p&gt;[ ]&lt;/p&gt;

&lt;h1 id=&quot;calculate-the-map-for-a-model-on-a-given-dataset&quot;&gt;calculate the mAP for a model on a given dataset&lt;/h1&gt;
&lt;p&gt;def evaluate_model(dataset, model, cfg):
	APs = list()
	for image_id in dataset.image_ids:
		# load image, bounding boxes and masks for the image id
		image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)
		# convert pixel values (e.g. center)
		scaled_image = mold_image(image, cfg)
		# convert image into one sample&lt;/p&gt;

&lt;p&gt;Running the example will make a prediction for each image in the train and test datasets and calculate the mAP for each.&lt;/p&gt;

&lt;p&gt;A mAP above 90% or 95% is a good score. We can see that the mAP score is good on both datasets, and perhaps slightly better on the test dataset, instead of the train dataset.&lt;/p&gt;

&lt;p&gt;This may be because the dataset is very small, and/or because the model could benefit from further training.&lt;/p&gt;

&lt;p&gt;Detecting Kangaroos in new Images&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">In this tutorial you would see how to apply state-of-the-art R-CNN architecture model built on the MS Coco dataset for Object Detection on a new Dataset. We use Transfer Learning for efficient and faster training epochs. You would learn how to Install the R-CNN Library, install the dataset we want to make predictions on, parse the annotation files for bounding boxes, Train Mask R-CNN Model on dataset using Transfer Learning.</summary></entry><entry><title type="html">Achieving 85% Accuracy in Image Classification task on Cifar10 Dataset with Keras Convolutional Neural Networks</title><link href="http://localhost:4000/achieving-85-accuracy-on-cifar-10-dataset/" rel="alternate" type="text/html" title="Achieving 85% Accuracy in Image Classification task on Cifar10 Dataset with Keras Convolutional Neural Networks" /><published>2020-07-11T00:00:00+01:00</published><updated>2020-07-11T00:00:00+01:00</updated><id>http://localhost:4000/achieving%2085%20accuracy%20on%20cifar%2010%20dataset</id><content type="html" xml:base="http://localhost:4000/achieving-85-accuracy-on-cifar-10-dataset/">&lt;p&gt;In this tutorial you would learn some methods that can be used to improve a model’s accuracy. This can be achieved in a few lines of code using Tensorflow by just importing required libraries. If you haven’t already, you can build a Tensorflow Image Classification model following the guide in the last post &lt;a href=&quot;&quot;&gt;How to Build an Image Classification API in Tensorflow&lt;/a&gt;. This is an overview of what we would be touching on in this tutorial:&lt;/p&gt;

&lt;h3&gt;Overview&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Improving Model’s Accuracy&lt;/li&gt;
  &lt;li&gt;Dropouts: Understanding how it reduces Overfitting&lt;/li&gt;
  &lt;li&gt;Batch Normalization&lt;/li&gt;
  &lt;li&gt;Buiding a Cifar10 Model with 85% Accuracy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Previous: &lt;a href=&quot;&quot;&gt;How to Build an Image Classification API in Tensorflow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Next: &lt;a href=&quot;&quot;&gt;Building an Image Classification API with TFX and GCP &lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Improving Model's Accuracy&lt;/h3&gt;

&lt;p&gt;In the last article we built a simple classifier model in Tensorflow. I achieved 75% accuracy after evaluating the test set which consists of 10000 Images which was not used in training. This gives us a view of how our model would perform in a real world scenario. Of-course, we aren’t going to use this model for any big projects anytime soon, but by practising on it gives us understanding that can be applied to bigger projects.&lt;/p&gt;

&lt;p&gt;Not all model’s after training can be significantly improved by applying this methods. It could be that the achitecture used at first didn’t train the model in the right way. In this case, you would need to change the layers used before getting any significant improvements. A very good way of knowing if a model can be improved is by plotting learning curves. This can be done in tensorflow in just a few lines of code.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/learning-curves-cifar10-dataset.webp&quot; class=&quot;img-fluid&quot; alt=&quot;Learning Curves Of Cifar10&quot; width=&quot;100%&quot; height=&quot;60vh&quot; /&gt;
As seen in the image above, around epochs 14, the validation set curve (orange) can be seen to have a strong dip. This tells us that if we increase the number of epochs or add regularization techniques like Dropouts and BatchNormalization, we can achieve better accuracy&lt;/p&gt;

&lt;p&gt;In this tutorial, we would look at some established methods of reducing overfitting and slowing-down convergence in our model which in turn gives us better accuracy. Let’s look at them now.&lt;/p&gt;

&lt;h3&gt;Dropouts&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;Dropout&lt;/b&gt; is a technique for addressing overfitting. The main idea here is for our neural network to randomly drop units during training. The reduction inparameters in each step of training has effect of regularization. Dropout has shown improvements in the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.&lt;/p&gt;

&lt;h3&gt;BatchNormalization&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;BatchNormalization&lt;/b&gt; normalizes the activation of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. It addresses the problem of internal covariate shift. It also acts as a regularizer, in some cases eliminating the need for Dropout. Batch Normalization achieves the same accuracy with fewer training steps thus speeding up the training process. This definition is cited from &lt;a href=&quot;https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/&quot;&gt;appliedmachinelearning.blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now that we understand the technique that would be applied during training to improve accuracy, let’s see how to implement it in code.&lt;/p&gt;

&lt;h3&gt;Buiding a Cifar10 Model with 85% Accuracy&lt;/h3&gt;

&lt;p&gt;Below is the code that introduces batch normalization and dropouts to our model’s ConvNet. For the full code including loading the dataset and normalizing it, refer to my github repo here &lt;a href=&quot;&quot;&gt;Image Classification with Cifar10 (Full) &lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
from keras.models import Sequential
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import BatchNormalization
from keras import regularizers
from keras.callbacks import LearningRateScheduler
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3))),
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(2, 2)),
model.add(Dropout(0.2))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same')),
model.add(Conv2D(64, (3, 3), activation='relu', padding='same')),
model.add(MaxPooling2D(2, 2)),
model.add(Dropout(0.2))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same')),
model.add(Conv2D(128, (3, 3), activation='relu', padding='same')),
model.add(MaxPooling2D(2, 2)),
model.add(Dropout(0.2))
model.add(Flatten()),
model.add(Dense(512, activation='relu')),
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

hist = model.fit(x_train, y_train_one_hot, 
          batch_size=64, epochs=25, 
           validation_split=0.2, verbose=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output of the above code implementation for Image classification task is shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, we trained our model for just 25% accuracy and achieved approx 85% accuracy. This is a significant development from when we only convolution and maxpooling layers to build our model. Training it for more epochs can as well give you more accuracy which you should try out by simply following the guide.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">In this tutorial you would learn some methods that can be used to improve a model’s accuracy. This can be achieved in a few lines of code using Tensorflow by just importing required libraries. If you haven’t already, you can build a Tensorflow Image Classification model following the guide in the last post How to Build an Image Classification API in Tensorflow. This is an overview of what we would be touching on in this tutorial:</summary></entry><entry><title type="html">How to Build an Image Classification API in Tensorflow</title><link href="http://localhost:4000/image-classification-api-in-tensorflow/" rel="alternate" type="text/html" title="How to Build an Image Classification API in Tensorflow" /><published>2020-06-28T00:00:00+01:00</published><updated>2020-06-28T00:00:00+01:00</updated><id>http://localhost:4000/image%20classification%20api%20in%20tensorflow</id><content type="html" xml:base="http://localhost:4000/image-classification-api-in-tensorflow/">&lt;p&gt;In this tutorial, you would learn how to build an Image Classification Model using Tensorflow on Google Colab. This tutorial is the first among three set. They go from buiding an Image Classifier to Improving accuracy in your model and finally Serving it for production through an API url Endpoint. To start off, here is the overview of all what we would be touching on.&lt;/p&gt;

&lt;h3&gt;Overview&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Image Classification In Computer Vision&lt;/li&gt;
  &lt;li&gt;Applications of Image Classification in World Industry&lt;/li&gt;
  &lt;li&gt;Steps to Build an Image Classification Model&lt;/li&gt;
  &lt;li&gt;Building the Model with Tensorflow (Keras)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next: &lt;a href=&quot;http://channelai.netlify.app/achieving-85-accuracy-on-cifar-10-dataset/&quot;&gt;Improving your Tensorflow Model with Regularization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Finally: &lt;a href=&quot;&quot;&gt;Building an Image Classification API with TFX and GCP &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now that you have an idea of the steps taking us through this tutorial, Let’s begin with it.&lt;/p&gt;

&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Starting off in Machine Learning can be Overwhelming, I say this because I’m currently in the process of experiencing the start off altogether. There are so many fields, opinions, doubts that can go through your mind on the process of choosing a path to follow. Sometimes, actually most times, It’s really cool to look at the big guys in the field that exude so much confidence showing that they know what they want. Also, there are lots of resources and articles around promising ways that would become a revelation to newcomers and map out the correct path for them. I just read some of those, and I’m more affected than when I was using my mind at a space to think for myself. My mood becomes let’s say negative. But I can’t be like that for long. I simply told myself I’m gonna learn them all by “doing”. It’s a big deal, perhaps the hardest part but with time it becomes a natural thing for you. That’s the way of life. Long story short, I decided to start implementing projects that I could add to my github, LinkedIn and blog.&lt;/p&gt;

&lt;p&gt;This tutorial is mainly for people starting off in “Computer Vision”, those that want to “know” and “do” Computer Vision. What I want you to understand is this: &lt;b&gt;“It’s all in the process. Those little steps sums into the big advancement”&lt;/b&gt;.. Well, at least I told myself that. OpenCV can wait, I’m gonna learn all the small steps involved but I’m gonna learn them very fast. I have the ability to, and I hope with the series of upcoming posts, you too can follow along and master the baby steps in Computer Vision(CV). Let’s get into more concrete writings.&lt;/p&gt;

&lt;h3&gt;Image Classification In Computer Vision&lt;/h3&gt;

&lt;p&gt;The term Image Classification refers to a task in CV that involves the process of assigning classes to an entire image or picture. It is sometimes referred to as Image recognition, which is a broader term that refers to various tasks that involves classifying the content of images.&lt;/p&gt;

&lt;p&gt;The task of helping computers to see, and make a sense or add meaning to what they see is a very hard task. Mainly because it does not just involve one but a series of steps are involved owning to the fact that real-world data or scenerio is unpredictable. Therefore, this is no longer a common task of pre-programmed rules giving accurate results. For computers to see, at basic level, they have to understand single still images before processing advanced high fps videos of which is our general goal as ML engineers and researchers.&lt;/p&gt;

&lt;p&gt;We come now to the problem of helping computers see. In accord, I decided to start of with the simplest problem and I think that should be Image Classification. In this problem&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We take a dataset that consists of a set of items in images and their corresponding labels&lt;/li&gt;
  &lt;li&gt;We train a model using the dataset so it can make predictions on new images by correctly assigning them to the right class&lt;/li&gt;
  &lt;li&gt;If it sees an image not among the class it was trained on, it would give it the label of the output with the highest probability&lt;/li&gt;
  &lt;li&gt;This tells us that if we want a model to recognize a thousand different items accurately, we would train it with a dataset outlining those items and their respective label. But ofcourse, this is not an effecient way of tackling the problem. We have millions of items in the world, not to talk of species of animals..xD&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As simple a task as Image Classification is it has some very impressive applications that has been very beneficial to diiferent industries. Let’s look at some Applications:&lt;/p&gt;

&lt;h3&gt;Applications of Image Classification in World Industry&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In Manufacturing: A system built with a classification model can help speed up production process by efficiently reporting bad/damaged items before they are packaged for distribution. By classifying items as bad or good after being trained with a lot of data in the respect of it’s use-case. The main benefit of this is that, it does this considerably faster than human workers and workforce is also reduced resulting in the decrease in “cost of production”, which in a way can lead to cheaper products.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In Medical: An image classifiction system trained with a lot of medical X-ray records depicting a patient eith a disease vs one without can be used to accurately diagnose the health condition of new patients. This can significantly reduce the time spent by medical practitioners conducting several tests before giving results, therby giving them more time to focus on other matters.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In Computer Vision: Image classification is a very important application in CV fields. At a basic level, it makes up the structure of an Object detection system which involves “localizing objects in an image by drawing a bounding box around them while also assigning objects to their correct class”. Image classification is used as the basis of many advanced CV applications, a good example is an autonomous vehicle. Image classification and Object detection is the main components making up the system though at advanced level. A self-driving car has to recognize objects it should not hit like pedestrains and road signs, it also has to localize them to undestand their path. This is a clear example of video/moving object detection.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In Agriculture: Models built on Image classification has a tremendous impact in the agricultural sector. They can be applied to numerous problems and can give very accurate results that significantly improves the conditions ans returns of farming. A popular example is an app built in Tensorflow that is used to identify early on, cassave crops with high probability of disease infection. This can help farmers increse yield / decrese loss by being aware of the health of their crops in advance.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are so many other applications of Image classification not mentioned. What I like best about ML models is that they make we humans more productive anywhere which they are applied. And that is why we keep researching ways to make them easier to build, cost effective and being able to be used for more complicated problems.&lt;/p&gt;

&lt;p&gt;Now I just gave some applications, another fun applications is integrating them in web and mobile applications for a number of services partaining to businesses. Today , you would build a classification model and use it as the backend of a web app. Now let’s look at the steps to build this model:&lt;/p&gt;

&lt;p&gt;In this tutorial, I’m using the Tensorflow ML framework and Keras backend. You dont need to install Tensorflow if you dont have it, we would be writing all the code in Google Colab, you can follow this link to open colab and create a new file … &lt;a href=&quot;&quot;&gt;Open Google Colab&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Steps to build an Image Classification Model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Import Keras and load Cifar10 Dataset&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding our Dataset &amp;amp; Image (shape)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Pre-processing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Image Processing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding the Stucture of Model&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Building and Training a ConvNet for Image Classification&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;if you are a total beginner and don’t understand some the terms used Like ConvNet, Image Processing and so on, I recommend taking this course by deeplearning.ai on Tensorflow. Or you can contact we directly giving me and I can recommend some resources that should help you get started.&lt;/p&gt;

&lt;p&gt;We want to start by importing Kera which would be what we use to build our model. Cifar10 is a dataset consisting of 10 different items and their corresponding label. We are gonna use this to train a model.&lt;/p&gt;

&lt;p&gt;My aim is to build a web application that uses the complete trained model as a back-end through an API endpoint. This web app would perform object recognition on images when a user uploads a given image and it would then using probability, pass as results the most likely class the object in that image belongs to. As expected, this would only work on 10 different classes of images from real-world examples making the user very limited in the amount of images he can classify( not that he doesn’t know the class of that image). In the next tutorial we can try out thsi same problem but on a larger dataset mainly Cifar100 i.e with 100 class of things. Let’s start writing some code!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use the following lines below to import keras along with cifar10&lt;/li&gt;
  &lt;li&gt;Store the data in the respective arrays to be used for training&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After those simple steps are completed, we can use the print function to see the shape of our training images&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;

from keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)
print('no_of_x_train:', len(x_train))

Output: 
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 1)
no_of_x_train: 50000S
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By running that piece of code,, we get the following output above. The shape of x_train printed out is (50000, 32, 32, 3). In simple words, the shape of our array tells us that our x_train consists of:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;50000 images (training data)&lt;/li&gt;
	&lt;li&gt;32 pixels in height (images)&lt;/li&gt;
	&lt;li&gt;32 pixels in width&lt;/li&gt;
	&lt;li&gt;3 pixels in depth (RGB values of image)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For our label training data y, we get the shape output as (50000, 1). This tells us we have 50000 label data in our training set with just one value&lt;/p&gt;

&lt;p&gt;That is the shape of our training data but keras stacks them in a 4D format, for easier processing when building our model. Now let’s try to see a full example of an image and label to better understand the logic. The code below helps us to that.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
print(x_train[0])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output looks like the image below:
&lt;img src=&quot;/assets/images/Blog/Blog-img/Computer_visualization_of_image_in_numbers.webp&quot; class=&quot;img-fluid&quot; alt=&quot;Computer visualization of Image in Numbers&quot; width=&quot;100%&quot; height=&quot;60vh&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Trying to visualize the image this way doesn’t help us a lot, although that’s how it is interpreted for the computer. The Red, green, and blue values in our 3 byte image are just a bunch of numbers that the computer can use to calculate the intensity of r,g,b at a pixel point. We can use the matplotlib package for a finer, data plot. Let’s import the package in the next lines of code&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/b&gt; imshow is a function that maps the numbered pixel values of x_train[0] like we saw previously, into the actual image it represents.We also print out the label, that is, the class this image belongs to of the 10 classes we have. Classes begin from index 0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
import matplotlib.pyplot as plt
img = plt.imshow(x_train[1])

print('The label is:', y_train[1])

Output:
The label is: [9]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The label showing as nine means that the second image in our training set (following index: 0 is first_img, 1 is second_img ) has a label/class of 9(truck) i.e the very last of the classes. With this we still do not know the class in words representing this image. The below image shows the conversion of numbers to the word class. Change the value of the printed x’s and labels in your colab environment, and visualize the different classes that gets printed out.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/number_to_word_class_cifar10.webp&quot; class=&quot;img-fluid&quot; alt=&quot;Numbers_to_words_class_representation_ImageClassification_in tensorflow&quot; width=&quot;100%&quot; height=&quot;30vh&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Data Pre-processing&lt;/h3&gt;

&lt;p&gt;In this step we want to preprocess our data because our labels as class number are not very helpful. We can hot-encode our label so that the model returns 1 for matched class and 0 for the rest unmatched classes(i.e 9,since there would always be one matched class). For a simple binary-logistic predictor, we would not need to perform this pre processing step mainly because our classes are just two. Class 0 and class 1. 
For example, building a model that predicts if a student is given admission(1) or not given(0) by training on past data X(scores on tests) and y(admission decision). In this case, we have only two possible classes and can continue without the need for data procesing.&lt;/p&gt;

&lt;p&gt;We can call our current problem a multi-variant/multi-label logistic problem. Using traditional Machine Learning method of mapping x’s to their labels, we would have to build a classifyer for all our 10 classes and optimize each of them separately,i.e 10 seperate theta parameter. But thankfully, we are using a framework that abstracts much of the work for us.&lt;/p&gt;

&lt;p&gt;This processing step is called one-hot encoding. It involves converting the labels into a set of 10 numbers where each number represents if the image belongs to that class or not. So if an image belongs to the first class, the first number of this set will be a 1 and all other numbers in this set will be a 0. The conversion table would look like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/one-hot-encoding-imageclassification.webp&quot; class=&quot;img-fluid&quot; alt=&quot;one-hot-encoding-imageclassification&quot; width=&quot;100%&quot; height=&quot;30vh&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now here we have been talking about one-hot encoding for a while, let’s write code for it in a few lines:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
import keras
y_train_one_hot = keras.utils.to_categorical(y_train, 10)
y_test_one_hot = keras.utils.to_categorical(y_test, 10)

print('The one hot label is:', y_train_one_hot[1])

Output: 
The one hot label is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the above code, the line &lt;b&gt;y_train_one_hot = keras.utils.to_categorical(y_train, 10)&lt;/b&gt; means that we want to take the array conatining the number labels of y_train and convert it to one-hot setting y_train_one_hot. The numeber 10 is a required paarmeter, it specifies the number of classes there are.&lt;/p&gt;

&lt;p&gt;We printed out the label of our second image(index 1/truck/label 9) and got the one-hot setting as above.&lt;/p&gt;

&lt;h3&gt;Processing Images(x)&lt;/h3&gt;
&lt;p&gt;To process our images , what we do is reduce the pixels values between 0 and 1 which would aid in training our neural network. The pixel values of x ranges between 0 - 255, to reduce them we can divide b 255. We first covert the datatype to float32 which is a datatype that can store decimal values. Let’s write code for this.&lt;/p&gt;

&lt;p&gt;We process our images before training mainly for our convolutions to easily find features to use for training therby reducing training period&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

x_train = x_train / 255
x_test = x_test / 255

x_train[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When we print our output,, like previously we get a bunch of numbers except that this time around they all fall in the range of 0 and 1. The process of reducing our image pixels in this way is called &lt;b&gt;&lt;em&gt;&lt;a href=&quot;https://channelai.netlify.app/introduction-to-machine-learning.md&quot;&gt;Normalization&lt;/a&gt;&lt;/em&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/normalized_form_of_cifar10_xtrain_after_image_processing.webp&quot; class=&quot;img-fluid&quot; alt=&quot;normalized_form_of_cifar10_xtrain_after_image-processing &quot; width=&quot;100%&quot; height=&quot;30vh&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This processing step makes our neural network to train faster and achieve better accuracy. Note: This processing is also carried out on the test set since when evaluating we want the same range of values as those used when training.&lt;/p&gt;

&lt;h3&gt;Understanding the Stucture of Model&lt;/h3&gt;

&lt;p&gt;We finally arrive at the most productive step, to train our model. This step just involves setting up a structure or architecture we want our model to have. We would add layers to our model in these sequence:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Add Convolution layer with zero-padding: A convolution is the simple application of a filter to an input that results in an activation. Repeated application of the same filter to an input results in a map of actitvation called a feature map, indicating the locations and strength of a detected feature in an input, such as an image.
	A concolution layer can be created by specifying both the number of filters to learn and the fixed size of each filetr,often called the kernel shape. This layer isolates the features in our images so that we can gather more information in less pixels. It actually ends up reducing the size of the pixels. The zero-padding works to produce the same output width and height as that of the input, what this means literally is that; we aren't losing any information by using zero-padding also called same-padding. The kind of padding used would either try to highlight the horizontal or vertical aspect(lines) of the image.&lt;/li&gt;&lt;br /&gt;
	&lt;li&gt;Add MaxPolling layer: Pooling layer provides an approach to downsampling feature maps by summarizing the presence of features in patches of the feature map. Maximum pooling or max pooling, is a pooling operation that calculates the maximum or largest value in each part of each feature map. It works by shrinking the pixel height and weight while still retaining relevant information. It is passed across the whole image, the size of the stride determines the quantity or perhaps quality of features that is passed to the output after MaxPooling is carried out.&lt;/li&gt;&lt;br /&gt;
	&lt;li&gt;Relu activation function: We use the relu activation in all layers except for the last layer which is a softmax. Relu (Rectified Linear Unit) is an activation that outputs the value of input X if x &amp;gt; 0 and outputs 0 if x &amp;lt; 0.&lt;/li&gt;&lt;br /&gt;
	&lt;li&gt;Softmax: Our last layer Softmax simply transforms the output of the previous layer into probability distributions. So we are able to match image classification based on the probability given by the model of each classes. And therefore, our model picks the class with the highest probability as the correct item detected in an image.&lt;/li&gt;&lt;br /&gt;
	&lt;li&gt;Sequential: Keras imports Sequential which is a library that holds all the types of layers we can use to build our model:
	&lt;ul style=&quot;list-style-type: disc;&quot;&gt;
		&lt;li&gt;Dense is the layer that combines all our parameters into a single dense package&lt;/li&gt;
		&lt;li&gt;Flatten is the layer that transforms our two-dimensional feature ma our image shape into one long vector&lt;/li&gt;
		&lt;li&gt;Dropout prevents overfitting in the layers&lt;/li&gt;
	&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Building the Model with Tensorflow (Keras)&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D

model = Sequential()
model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3))),
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2)),
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu')),
model.add(Conv2D(64, (3, 3), activation='relu')),
      #model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(2, 2)),
model.add(Dropout(0.25))

model.add(Flatten()),
model.add(Dense(1024, activation='relu')),
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))



model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
hist = model.fit(x_train, y_train_one_hot, 
           batch_size=32, epochs=15, 
           validation_split=0.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After training , I got an accuracy of 79% on my training set and 75% on my validation set. It’s quite noticeable that the usage of dropouts after layers helped in minimizing overfitting. I’m almost underfitted but I can not make that claim as I got quite a good accuracy on my validation set. U should try tweaking different values to fully understand this and see if you can improve the accuracy of your model. Some hyper-parameters that you should consider when tuning includes: epochs, number of ConvNets(add more with higher depths), dropouts.&lt;/p&gt;

&lt;p&gt;Before using this model to make some predictions, let’s plot some learning curves that would help us understand how well our model trained. this step should help us understand overfitting, underfitting, unsteady training and so on. This can help us to decide steps to take that can help improve the model.&lt;/p&gt;

&lt;h4&gt;Plot showing Model Loss during Training&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/model_loss_plot_learning_curve.webp&quot; class=&quot;img-fluid&quot; alt=&quot;model_loss_plot_learning_curve&quot; width=&quot;100%&quot; height=&quot;30vh&quot; /&gt;
…..&lt;/p&gt;
&lt;p style=&quot;padding-top: 5%&quot;&gt;&lt;/p&gt;
&lt;h4&gt;Plot showing Model Accuracy during Training&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/model_accuracy_plot_learning_curve.webp&quot; class=&quot;img-fluid&quot; alt=&quot;model_accuracy_plot_learning_curve&quot; width=&quot;100%&quot; height=&quot;30vh&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From the above plots we see that, we had a steady training without overfitting our model.
Now for the last step, we want to evaluate our model using the test set and also make predictions using entirely new images. You can do this by getting images that fall into any one of the classes as we have in our dataset. The code below would enable you to choose multiple files from your storage for prediction.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
model.evaluate(x_test, y_test_one_hot)[1]
model.save('chel_cifar10_model_OR.h5')

import numpy as np
from skimage import data, color, feature, transform
from skimage.transform import resize
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()
for fn in uploaded.keys():

path = '/content/' + fn
img = image.load_img(path, target_size=(32, 32))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

#images = np.vstack([x])
probabilities = model.predict(images, batch_size=10)
print(probabilities[0])

number_to_class = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
index = np.argsort(probabilities[0,:])
print(&quot;Most likely class:&quot;, number_to_class[index[9]], &quot;-- Probability:&quot;, probabilities[0,index[9]])
print(&quot;Second most likely class:&quot;, number_to_class[index[8]], &quot;-- Probability:&quot;, probabilities[0,index[8]])
print(&quot;Third most likely class:&quot;, number_to_class[index[7]], &quot;-- Probability:&quot;, probabilities[0,index[7]])
print(&quot;Fourth most likely class:&quot;, number_to_class[index[6]], &quot;-- Probability:&quot;, probabilities[0,index[6]])
print(&quot;Fifth most likely class:&quot;, number_to_class[index[5]], &quot;-- Probability:&quot;, probabilities[0,index[5]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code evaluates our model using test set, saves the trained model in a .h5 format and also we are able to upload files for prediction by the files library from keras. Then we converted the output numbers into words_class as it’s easier to understand that way. The last bit of code enables us to do that.&lt;/p&gt;

&lt;p&gt;After training the model and evaluating on the test set (x_test), I got an accuracy of 75%. This means that, our classifier would classify correctly only 75% of new unseen images we feed it.&lt;/p&gt;

&lt;p&gt;Test out different images to see how well the model you built classifies them.&lt;/p&gt;

&lt;p&gt;In the part 2 of this article, let’s look at how to Improve significantly our built model’s accuracy by Introducing some new concepts that would prevent over-fitting and slow down convergence. &lt;a href=&quot;&quot;&gt;Next Article: Improving your Tensorflow Model with Dropouts and Batch Normalization&lt;/a&gt;&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">In this tutorial, you would learn how to build an Image Classification Model using Tensorflow on Google Colab. This tutorial is the first among three set. They go from buiding an Image Classifier to Improving accuracy in your model and finally Serving it for production through an API url Endpoint. To start off, here is the overview of all what we would be touching on.</summary></entry><entry><title type="html">Introduction to Generative Models and GANs - What are GANs?</title><link href="http://localhost:4000/introduction-to-generative-adversarial-netowrks/" rel="alternate" type="text/html" title="Introduction to Generative Models and GANs - What are GANs?" /><published>2020-06-22T00:00:00+01:00</published><updated>2020-06-22T00:00:00+01:00</updated><id>http://localhost:4000/introduction%20to%20generative%20adversarial%20netowrks</id><content type="html" xml:base="http://localhost:4000/introduction-to-generative-adversarial-netowrks/">&lt;h3&gt;Overview&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Generative Models and GANs - This article will give a simplified intoduction to GANs that you can fully grasp without prior knowledge of the basics&lt;/li&gt;
  &lt;li&gt;This article will explain briefly the structure of GANs, what they achieve and how they are trained&lt;/li&gt;
  &lt;li&gt;Some Intruiging-real world applications of GANs awaits you– Let’s begin!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;I first heard about GANs not quite long ago, as it is, I’m relatively a new-comer to the field. I came across it first while scrolling a filtered results for Computer Vision on Analytics Vidyha website. The title of the article was actually what made me click it “Generative Models: The Magic of Computer Vision”. I started reading this article and I was nothing short of amazed-completely, you know, I never knew something like what I read and saw was possible at this time, but well, it actually isn’t even &lt;em&gt;that&lt;/em&gt; new. If you are somewhat just hearing it for the first time, try and be amazed by this.&lt;/p&gt;

&lt;p&gt;Can you guess where the below collection of images came from:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\Gans2.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;How about these ones:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\Gans3.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Well, all of the object and faces you see in these images have been generated single-handedly by a computer-vision model called Generative Adversarial Networks (GANs)!. Awesome right? There’s so much more to see.&lt;/p&gt;

&lt;p&gt;Being someone with a growing interest in Computer Vision and Virtual Reality, I loved it so much. In short, my mind started racing through the wonderful possibilities of GANs in Virtual Reality, of course, all those would take a lot of work in reserach but who knew we would have GANs performing at this level in just 2020.&lt;/p&gt;

&lt;p&gt;With this article, I hope to give you a simple Introduction to GANs with all the necessary and important aspects of it, that you can go on with to explore ideas in branches of your interest. We would also look at some of their applications and how GANs come to give such exciting results that spells creativity.&lt;/p&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;What are Generative Models&lt;/li&gt;
  &lt;li&gt;Structure of Generative Models&lt;/li&gt;
  &lt;li&gt;Types of Generative Models&lt;/li&gt;
  &lt;li&gt;Applications of Generative Models&lt;/li&gt;
  &lt;li&gt;Getting Started with GANs - Projects &amp;amp; Opensource&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;What are Generative Models&lt;/h3&gt;

&lt;p&gt;“&lt;em&gt;Generative Adversarial networks is the most interesting idea in the last 10 years in Machine Learning&lt;/em&gt;”- &lt;b&gt;Yann Le Cun&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Generative Adversarial Networks, or GANs for short, are a type of neural network used for machine learning, computer vision, and other forms of artificial intelligence. Generative modeling is an unsupervised learning task in machine learning in which regularities and patterns of input data are discovered and learned so that a model can be used to generate and output new examples that can plausibly be taken from the original data set.&lt;/p&gt;

&lt;p&gt;Generative Adversarial nets were recently introduced (In the past 7 years or so) as a novel way to train a generative model, i.e create a model that is able to generate data. They consists of two ‘adversarial’ networks: a generative model G that captures the data distribution and a distributive model D that estimates the probability that a sample came from the training data rather than from G.&lt;/p&gt;

&lt;p&gt;A generative adversarial network, GAN for short, consists of two main structure that makes up the whole basis of its operation. They are called the &lt;b&gt;Generator&lt;/b&gt; and &lt;b&gt;Discriminator&lt;/b&gt;. These two neural networks are pitted against each other in a zero-sum game, whereby the first network, the generator, is tasked with fooling the second network.&lt;/p&gt;

&lt;p&gt;A simple GAN can be said to be made up of two dataset, one of them is called the true or real-world dataset, the other can be called the fake dataset. The Generator is the model that distributes fake data into the system while the discriminator gives as input X, the real data. This two inputs are passed into the model, and every iteration/epochs, the discriminator would have to discern if each image sample comes from the real or fake dataset. At the start of training, the discriminator almost always spots the fake data, whereby, the generator model has to change its weights(during training) inorder to reduce the cost/error made and once again pushes a new improved set of data to the discriminator for inspection. This is what happens at training periods, on each epochs until a desired level of accuracy is achieved. The overall system and purpose of GANs is to obatin a level of cost that the discriminator starts to guess datas from the generator as “real ones”.&lt;/p&gt;

&lt;p&gt;While the discriminator tries to distinguish between the real and fake sets of data , the generator attepts to create a plausible example of the same data set by updating its weights/parameters. The Generator models are designed to deceive the discrimination model, by trying  to generate plausible examples that fits among the real dataset. Our hope is that the two networks, when they face each other, will get better and better until the end result is a generator network that produces photorealistic outputs.&lt;/p&gt;

&lt;p&gt;The fake samples are generated by some randon noise from looking at the real data, they are passed on to the discriminator whose input is both fake samples as well as samples from our real data set. The discriminator than makes a binary decision about whether the image supplied, z, is a real image D(z)= 1, or a fake image, D(z)=0.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\D&amp;amp;G_Gans.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For example, a GAN trained on photographs can create a new photograph that appears to human observers at least superficially authentic and has many realistic characteristics. A popular real-world application of GAN; GANs have been used to produce new celebrities who are not real people. Using a training kit, the technique learns to create images of real-life celebrities, real-face celebrities and non-real face celebrities.&lt;/p&gt;

&lt;p&gt;So a GAN (generator network) can start with a matrix of noise pixels and try to change them in what an image classifier would call a “cat.” Instead of taking raw data, the generator can trace back to the original input data (e.g. a photo of a cat) and then try to generate output from which the input of the data would be mapped. The new data is not bound to a single data set, but is created from a set of data points (i.e. an array of images or a set of data sets).&lt;/p&gt;

&lt;p&gt;Back in 2014, Ian Goodfellow suggested the idea of two neural networks competing or working together. For some networks, parallel training means an improvement in skills, for others it is a question of perspective.&lt;/p&gt;

&lt;p&gt;One neural network tries to generate realistic data, the other network tries to distinguish what the generator network generates. The discrimination network updates its parameters to ensure that the fake data is selected from the real data. Note: GANs can be used to model data distributions, but nowadays they are mainly used for images). The generator networks use the discriminators as a loss function and update their parameters after generating data that appears more realistic.&lt;/p&gt;

&lt;p&gt;GAN is a recently developed machine learning framework that proposes creative realistic representations of the real data distribution of images and other data. As mentioned above, a sample image can be used to create images that are superficially authentic to human observers by mapping sets of feature noise from the input to an output with close relation&lt;/p&gt;

&lt;p&gt;Cited works from:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/comprehensive-introduction-to-turing-learning-and-gans-part-2-fd8e4a70775&quot;&gt;towardsdatascience(medium)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/&quot;&gt;MachineLearning Mastery&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://deepai.org/machine-learning-glossary-and-terms/conditional-adversarial-network&quot;&gt;Deepai.org&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_adversarial_network&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://bdtechtalks.com/2018/05/28/generative-adversarial-networks-artificial-intelligence-ian-goodfellow/&quot;&gt;BDtechtalks&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Chel</name></author><summary type="html">Overview Generative Models and GANs - This article will give a simplified intoduction to GANs that you can fully grasp without prior knowledge of the basics This article will explain briefly the structure of GANs, what they achieve and how they are trained Some Intruiging-real world applications of GANs awaits you– Let’s begin!</summary></entry><entry><title type="html">Vectorization - How to Vectorize ML Algorithms with MATLAB</title><link href="http://localhost:4000/vectorization-in-machine-learning-with-matlab/" rel="alternate" type="text/html" title="Vectorization - How to Vectorize ML Algorithms with MATLAB" /><published>2020-06-16T00:00:00+01:00</published><updated>2020-06-16T00:00:00+01:00</updated><id>http://localhost:4000/vectorization%20in%20machine%20learning%20with%20matlab</id><content type="html" xml:base="http://localhost:4000/vectorization-in-machine-learning-with-matlab/">&lt;p&gt;In my previous post, I gave a simplified introduction to Machine Learning for beginners. It therefore brings the need for me to write a post on “Vectorization”. You might be hearing it for the first time or you have possibly come across it sometime. Either one of those, I can tell you that it isn’t a difficult subject, in fact in the field of Machine Learning I found it much easier than a normal iterative code (for &amp;amp; while loop). Now lets begin, by the end of this post I want you to understand what vectorization is, it’s application and how to use it in your ML Implementation.&lt;/p&gt;

&lt;p&gt;The title of this post actually says “Vectorization in ML with MATLAB”, so you can tell I would be teaching you how to vectorize your code with MATLAB as the programming language, but you should know that almost all language codes can be vectorized. Now let’s look at a simplified definition of vectorization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Vectorization&lt;/em&gt;&lt;/strong&gt; is a method of writing codes that makes them run much faster. It applies operators to “multiple” operands without the use of loops, these operands are usually a matrices or vectors.&lt;/p&gt;

&lt;p&gt;A more official definition, cited from &lt;a href=&quot;https://www.quantifisolutions.com&quot;&gt;Quantifisolutions website&lt;/a&gt;.&lt;br /&gt;Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at once.. In a vectorized calculation, all elements of the vector (array) can be added in one calculation step.&lt;/p&gt;

&lt;p&gt;Now let’s look into a basic explanation for it. You want to perform calculations on some numbers or in our case, Data, you have to write a piece of code to do the computation for you. In Machine Learning, 80% of the code we are writing is an iterative function, looping over a fixed number of training examples or sort. For example, in &lt;a href=&quot;https://channelai.netlify.app/linear-regression-simplified/&quot;&gt;Linear Regression&lt;/a&gt;, to build a model or predictor we have to compute the cost function and gradient descent over all our training data, and to do this we more than likely need to use loops, that’s where vectorization comes in. Let’s look at what makes vectorization possible in Machine Learning. We would be touching mainly on Matrix and Vectors in this post.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Matrices&lt;/em&gt;&lt;/strong&gt; are in simple form two-dimensional arrays. That is, they are made up of numbers in a 2D shape or size.Matrices are usually denoted by uppercase names in Matlab.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Array_programming&quot;&gt;Arrays(Wikipedia)&lt;/a&gt; on the other hand is a set of numbers arranged in list format, as such, a Matrix can be called an array but not the other way round, simply because a Matrix although being in 2D shape is still a list of numbers in “rows” and “columns”. Let’s take an example so you can understand better.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Vectors&lt;/em&gt;&lt;/strong&gt; are one-dimensional arrays. They are similar to matrix with the exception that they have only 1 dimension. So basically, a Vector is a matrix with one column and many rows. So vectors are a subset of matrices.&lt;/p&gt;

&lt;p&gt;Scalars on the other hand means that an object is a single value, not a vector or matrix. In other words, real numbers or integer values like 2.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Example 1:

Array = [2,3,4,6,7,8] %list of num in square brackets

Matrix =[2,3,4;6,7,8] % 2x3 Matrix with 2 rows and 3 columns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the above example,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You can write matrices by separating rows with semicolon(;)&lt;/li&gt;
  &lt;li&gt;By adding a semicolon, we define a new row and also columns&lt;/li&gt;
  &lt;li&gt;Not adding a semicolon makes it an array&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note: We have higher dimensions of Matrices in 3D, 4D etc,, you wouldn’t need to understand it for implementing Machine learning &lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;Getting Familiar with Dimensions in Matrix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;

mat_1 = [4,6;7,8] % A 2x2 matrix (2 rows and 2 columns)

mat_2 = [1,2,3;4,5,6] % A 2x3 matrix (2 rows and 3 columns)

mat_3 = [1,2,5,6;3,4,7,8] % A 2x4 matrix (2 rows and 4 columns)

mat_4 = [1,2;3,4;5,6] % A 3x2 matrix (3 rows and 2 columns)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Check out the visualiztion of the Matrices above in the image below. This would give you a better sense of how they are formed or their structure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/matrix_formation.webp&quot; class=&quot;img-fluid&quot; alt=&quot;ChannelAI Homepage: Artificial Intelligence&quot; width=&quot;100%&quot; height=&quot;60vh&quot; /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Vectorization in Machine Learning is done or carried out when we want to perform calculations on Matrix-Matrix or Matrix-Vectors. Most of our data in ML is stored and read in rows and colums. In the code box below are some examples showing operations between matrix and Vectors, but before you learn about them I would like to list a few rules guiding how we carry out operations in matlab on matrices.&lt;/p&gt;

&lt;h4&gt;Rules Guiding how to Combine Arrays in Matlab&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To add or subtract two matrices, their dimensions must be the same. You cannot use the Addition/Subtraction operator on Matrix of unequal dimensions. Example: Adding a 2x3 and 3x2 matrix throws an error. Addition on Matices are Element-wise, so you simply add or subtract each corresponding element.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Matrix-Vector Multiplication: The result is a vector. In a Matrix-Vector muliplication the number of “columns” of the matrix must be equal to the number of “rows” of the vector. An m x n matrix multiplied by an n x 1 vector results in an m x 1 vector.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Matrix-Matrix Multiplication: We multiply two matrices by breaking it into several vector multiplications and concatenating the result. An m x n matrix multiplied by an n x o matrix results in an m x o matrix. To multiply two matrices, the number of “columns” of the first matrix must equal the number of “rows” of the second matrix.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In scalar multiplication, we simply multiply every element by the scalar value, same applies for scalar addition or division.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot; style=&quot;padding-bottom: 0;&quot;&gt;
	&lt;h4 style=&quot;padding-top: 0;&quot;&gt;Matrix-Vector Multiplication&lt;/h4&gt;
% Initialize matrix A 
A = [1, 2, 3; 4, 5, 6;7, 8, 9] 
% Initialize vector v 
v = [1; 1; 1] 
% Multiply A * v
Av = A * v
Results:
A =
   1   2   3
   4   5   6
   7   8   9
v =
   1
   1
   1
Av =
   6
   15
   24
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;css&quot; style=&quot;padding-bottom: 0;&quot;&gt;
	&lt;h4 style=&quot;padding-top: 0;&quot;&gt;Matrix-Matrix Multiplication&lt;/h4&gt;
% Initialize a 3 by 2 matrix 
A = [1, 2; 3, 4;5, 6]
% Initialize a 2 by 1 matrix 
B = [1; 2] 
% We expect a resulting matrix of (3 by 2)*(2 by 1) = (3 by 1) 
mult_AB = A*B
Results:
A =
   1   2
   3   4
   5   6
B =
   1
   2
mult_AB =
   5
   11
   17

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Example 2:

vect_1 = [1;2;3;6;7;8] % A column vector with 6 values

mat_1 = [1,3,5;8,7,6] % A 2x3 Matrix


&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;REASONS FOR VECTORIZING CODE&lt;/h4&gt;
&lt;ul style=&quot;padding: 5;&quot;&gt;
	&lt;li&gt;&lt;b&gt;Appearance&lt;/b&gt;: Vectorized mathematical code appears more like the maths we are used to from high-school, making the code easier to understand.&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Less Error Prone&lt;/b&gt;: Without loops, vectorized code is often shorter. Fewer lines of code mean fewer opportunities to introduce programming errors.&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Performance&lt;/b&gt;: Vectorized code often runs much faster than the corresponding code conatining loops&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that we have gone over a few reasons for using vectorized codes, I would like to show you code that outlines the difference in using loops vs vectorization for writing codes. This alone would show you the main idea of vectorization. Although you should know that as model size increases, so does the technique for carrying out vectorization. It gets more advanced but to tell the truth, it’s nothing you can’t handle, as long as you are doing Machine Learning, the concept remains the same as the example below. Let’s write code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Example 4:

This code computes the sine of 1001 values ranging from 0 to 10:
Using Loops:

i = 0;
for t = 0:.01:10
	i = i + 1;
	y(i) = sin(t);
end	

Using Vectorization:

t = 0:.01:10;
y = sin(t);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So there you have it, a few example codes and reasons, more than sufficient why it is advised to vectorize code when Implementing ML. Now that you’ve learnt the basics of Matrix, vectors and code vectorization you can now ahead and use this concept in your work. For reference, all the code for my last post in Linear regression were vectorized, so you can start learning from there how this works in ML and if you want a deeper understanding, check out this course by Vanderblit University on Coursera: &lt;a href=&quot;&quot;&gt;Introduction to Programming with MATLAB&lt;/a&gt;. It covers almost all you need to use Matlab to advanced level. I suggest you enroll if you want to use Matlab as your main programming lang for Machine Learning. Thanks for reading along, I do hope you learnt a thing or two about Vectorization. Even if u feel like you didn’t get much, don’t worry about it, all you need is some practice and you should understand it fully in a short while. If you have any questions related or closely related to our topic, I would very much like to hear it, simply leave a comment below.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">In my previous post, I gave a simplified introduction to Machine Learning for beginners. It therefore brings the need for me to write a post on “Vectorization”. You might be hearing it for the first time or you have possibly come across it sometime. Either one of those, I can tell you that it isn’t a difficult subject, in fact in the field of Machine Learning I found it much easier than a normal iterative code (for &amp;amp; while loop). Now lets begin, by the end of this post I want you to understand what vectorization is, it’s application and how to use it in your ML Implementation.</summary></entry><entry><title type="html">Introduction to Linear Regression - Creating a Simple Learning Predictor</title><link href="http://localhost:4000/linear-regression-simplified/" rel="alternate" type="text/html" title="Introduction to Linear Regression - Creating a Simple Learning Predictor" /><published>2020-05-31T00:00:00+01:00</published><updated>2020-05-31T00:00:00+01:00</updated><id>http://localhost:4000/linear%20regression%20simplified</id><content type="html" xml:base="http://localhost:4000/linear-regression-simplified/">&lt;p&gt;So now that you know a little bit about Machine Learning. It becomes natural for you to understand how you can use it to build models that are capable of making decisions at minimal level. The way we achieve this is the use of Machine Learning Algorithms that were developed several years back by experts in the field.&lt;/p&gt;

&lt;p&gt;The way these algoritm are capable of learning from real-world data to be able to make predictions is mostly because the mathematical computations on which they are built support or are proven to learn or map data to specific labels through probability and with experience.&lt;/p&gt;

&lt;p&gt;In this article, you would be introduced to one of the simplest and popular ML Algorithm called &lt;strong&gt;Linear Regression&lt;/strong&gt;. It is recommended that you read our tutorial on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;Vectorization with Matlab&lt;/a&gt;&lt;/em&gt; if you haven’t already as we would be using vectorization to implement our LR model for faster and easier bug debugging.&lt;/p&gt;

&lt;p&gt;Linear Regression is a Machine Learning algorithm that is used for predictions of “continuous /non-classified data”. To better understand it, let’s use a very popular example. Say, you want to predict the prices of particular houses,height of students in a class, weight and so on. This examples define continuous data, that is, they stand alone and are not grouped into classes. This is in contrast to a second learning algorithm called Logistic Regression which we would be looking at in the next post. Before we proceed to the implementation of Linear Regression, i want to give a general idea or intuition about what an ML model is trying to achieve and how it works.&lt;/p&gt;

&lt;p&gt;I learnt Linear Regression from the Stanford University &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;Machine Learning course on Coursera&lt;/a&gt;&lt;/em&gt; taught by Professor Andrew Ng. I feel like i could not have gotten a better understanding if i had learnt it elsewhere, Andrew always wanted to give the students an intuition about any new algorithm we were taking on and i loved it. It made me understand exactly how that algo was different from the previous one even before we started learning the maths behind it. I should say, that’s one of the best course or teaching i have ever received. Now i have this understanding of the different algoritms that even if i were to forget the correct code to implement them i still have a very good grasp of what they are doing and i think that’s very important.&lt;/p&gt;

&lt;p&gt;Now i would give you guys that intuition at the start of every algo you would be learning.&lt;/p&gt;

&lt;p&gt;You have some datasets in continuous values(because we are doing LinearRegrssion) and you want to go about training a model to the point that it achieves a preferred level of accuracy that you consider good enough for the use you want. Yh yh, we want a model that can do that for us but &lt;b&gt;how&lt;/b&gt; does it come to achieve this?. In Machine Learning we have two main types of model learning; supervised and unsupervised. To get more insights on them, read our full article on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;&lt;b&gt;Machine Learning&lt;/b&gt;&lt;/a&gt;&lt;/em&gt;. In Linear Regression we are carrying out the supervised part of learning, think of it as supervised beacuse we are providing some labels or correct values that we want our model to learn from. It goes exactly like this: we have a data set we a number of examples, each of this examples has two values in a row (x and y). The x denotes the value that is fed into the model and y denoting the output of the model. These x’s and y’s are both fed to the model during the training step/phase, therefore the name supervised. 
When we begin to do the math of it, i would explain i details what these terms mean and you should hopefully understand it better.&lt;/p&gt;

&lt;p&gt;We have some specific steps of training that we would take iteratively or repeatedly, the main purpose of this is to reduce the errors generated at each trainng step or loop. Its almost as easy as that. Now we come to the algoritms involoved that helps us achieve that.&lt;/p&gt;

&lt;p&gt;THE THREE MAIN CODE IMPLEMENTATION WHEN TRAINING A LINEAR REGRESSION ALGORITHM:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Prediction function&lt;/li&gt;
  &lt;li&gt;Cost Function&lt;/li&gt;
  &lt;li&gt;Gradient Descent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s look at each of them closely. We know we want an accurate “predictor”, and for that to be, three things has to happen: Our model could start by randomly guessing or well thinking at least it’s guessing correctly but the model would definitely be wrong because initially it hasn’t mapped a function to the data, now we use the cost function to calculate the errors gotten on all our training examples of that step in the loop,that is. the errors when our predictor tried to guess what the output y’s of each x’s were. Finally, the Gradient Descent algo tries to fit our model better by reducing the amount of those errors until it converges to a point that the errors are minimal or can’t be reduced further. Now i would define all the most of the terms used in Linear Regression so you can understand better what each is doing.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Dataset: Dataset is a collection of data, usually data fron real world affairs that can be used to train a model. It can be in either &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;structured&lt;/a&gt;&lt;/em&gt; or &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;unstructured&lt;/a&gt;&lt;/em&gt; form. The stuctured type of data can be divided into &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;supervised&lt;/a&gt;&lt;/em&gt; or &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;unsupervised&lt;/a&gt;&lt;/em&gt; datasets. Datasets sizes ranges from hundreds of trainig examples to as much as millions. Data is usually the first step of model training referred informally as “collecting data”.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Algorithm: A set of mathematical or statistical calculations that is used to compute for numbers, they are proven to give us our answers if implemented in the correct order. Algorithms are found in different fields of study, each constucted to be abstracted will also supporting some higher-level logic for the purpose it’s used.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Training Examples: Usually found in the dataset, training examples in Linear Regression consists of some x’s and y’s which we want our model to learn from considering they are the correct form of matching or mapping that we want. Think of the input x as any subject that can be used to ‘determine’ an effect or some other number. And y being that number that was the result of exactly what &lt;b&gt;x&lt;/b&gt; is. So let’s just say they are dependable of themselves.They are denoted by &lt;b&gt;m&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cost Function: A function in Machine Learning that is always given the task of finding errors after one iteration of learning or after our “predictor” as tried to guess the output of all x’s. Different ML algorithms would come with cost functions that are constructed for exactly how they are used or what concept they support, that in most cases would not work for a different Ml Algorithm. We would call the output y the model is trying to predict &lt;b&gt;y hat&lt;/b&gt;. Consequently, this cost-function is the difference between yhat and y matched be some parameter theta. They are denoted by capital &lt;b&gt;J&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parameters: In Linear Regression, we are trying to predict our y’s given x’s. How we achieve this is that we use parameters called theta to map the function for us. These theta are practically the ones that gives us our errors and by changing them, we can get smaller errors and so on. They are what the model is built upon. In Linear Regression, parameters theta multiplied by our input data x gives us our prediction of ouput y. So you can see how important they are, we use gradient descent to change or reduce the errors calculated by cost function and by changing those errors our parameters theta are defining the predictions a bit more correctly, that is, they are getting better.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gradient Descent: Gradient Deascent is a powerful algorithm that is used in Linear Regression to update theta to a value that gives less errors. It is an iterative function that keeps updating theta in every cycle of the loop until theta converges or gets to the point that it’s reduction if any becomes insignificant.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So now you know the three main steps involved in Linear Regression and hopefully the basic definitions of those terms gave you a better idea of how we train a Predictor or model. Now we can go ahead to implement all these in code. For this tutorial, I would get a dataset of one feature X and output Y from &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;https://www.openml.org/search?type=data&quot;&gt;Open ML&lt;/a&gt;&lt;/em&gt;,a platform where ML engineers and data scientists can collaborate on projects or share datasets. I will be implementing and testing the code written here on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;MATLAB&lt;/a&gt;&lt;/em&gt;, a platform for carrying out mathematical computations and linear algebra. It comes with a free-trial, but to use for an extended period of time, a fee has to be paid. If you want to follow along, you can either use MATLAB or OCTAVE. To set up octave, read our article on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;how to set up octave on windows&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;So I downloaded a dataset from open ML to my PC, I can then login to my MATLAB acct, upload the data, and start building a Linear Regression predictor. Let’s Begin&lt;/p&gt;

&lt;p&gt;AIM OF PREDICTOR&lt;/p&gt;

&lt;p&gt;In this tutorial we would be building a simple model that would use a number of input features x to predict the ‘price’ a building will sell for.&lt;/p&gt;

&lt;p&gt;DATASET&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt;This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.

It contains 19 house features plus the price and the id columns, along with 21613 observations. It's a great dataset for evaluating simple regression models.&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can download this dataset from OpenML &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;https://www.openml.org/d/42092&quot;&gt;here&lt;/a&gt;&lt;/em&gt;. As stated it is a multi-varaint dataset or simply, it has multiple features in total 19, and 21613 training examples. For this tutorial, we would be using 3 features and 100 training examples.To implement for a uni-variant model, you can follow the whole process but instead load just one feature into the x variable. You would learn about it all soon.&lt;/p&gt;

&lt;p&gt;FEATURES&lt;/p&gt;

&lt;p&gt;The 3 features we would be giving our variable x are &lt;strong&gt;number of bedrooms&lt;/strong&gt;, &lt;strong&gt;sqft of living area&lt;/strong&gt; and &lt;strong&gt;year built&lt;/strong&gt;. There a a lot more features but the reason i chose those 3 is because they seem like the factors that play the largest role of influence on the price a customer would like to pay for a house. Also including similar features like &lt;strong&gt;sqft of basement , sqft of upperlevels&lt;/strong&gt; and so on would end up making the features redundant (repetitive or duplicating). Take a look at the full features in our dataset.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\lr-feature-list.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To set off,we would be using the list as a guide to know the order of the steps it takes to build our model.You can always refer back to this, as a reminder of what steps you should be implementing at what time.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Feature Normalization&lt;/li&gt;
  &lt;li&gt;Plot the Data&lt;/li&gt;
  &lt;li&gt;Compute for the Cost Function&lt;/li&gt;
  &lt;li&gt;Gradient Descent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There is a step included that we have not yet covered, let’s do that now.&lt;/p&gt;

&lt;p&gt;Feature Normalization is a way to neutralize the wide range of values we might have in our dataset. It simply reduces how far apart how data is in their real values in numbers. For example, in  our house_sales dataset we can observe that the difference between the year_built and no_of_bedrooms features is so wide apart and can cause irregularities for our model to learn accurately in lesser time. The way to combat this is simply to normalize our data. In Machine Learning this is referred to as “Feature Normalization”.&lt;/p&gt;

&lt;p&gt;Plotting data is a good way to understand our data, it can be done at different steps when implementing ML algorithm, apart from the purpose of visualization, it also helps us for debugging just by looking at the curves and shapes our data takes.You would learn more about this in future lessons. To plot the data onto a graph, we use a set of built-in functions from MATLAB (same applies in Octave). Whenever i use some new built-in function in our code I would give a brief explanation of what it does, for this reason, anyline starting with a “%” signifies an explanation of the code on the next line. The “%” sign is the official way used to write comments in Matlab.&lt;/p&gt;

&lt;p&gt;Now let’s begin with the first step on the list, which is loading our data into MATLAB Environment normalizing our features so when plotting we can have a better idea of our data.&lt;/p&gt;
&lt;h4&gt;Load the Data into Environment&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
% Load Data
data = load('dataset_');
% Load into X , row 1-100 and columns 4 , 6 &amp;amp; 15
X = data(1:100, [4,6,15])
% Load into y, row 1-100 column 3 (price)
y = data(1:100, 3)
% Denotes the number of training examples , length (100)
m = length(y)
% Call the pre-defined func &quot;featureNormalization&quot;
% It takes one value X and computes three values, (X_normalized, mean of X , range of X)
[X, mu, sigma] = featureNormalize(X)
% Plot the dataset using the normalized X
plot(X,y,'r*')
% Print out first 10 examples from the dataset
fprintf(' x = [%.0f %.0f %.0f], y = %.0f \n', [X(1:10,:) y(1:10,:)]');
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;FeatureNormalization.m&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Xfunction [X_norm, mu, sigma] = featureNormalize(X) 
%   FEATURENORMALIZE(X) returns a normalized version of X where the mean value of each feature is 0 and the standard deviation is 1. 
% This is often a good preprocessing step to do when working with learning algorithms.

% You need to set these values correctly
X_norm = X;
mu = zeros(1, size(X, 2));
sigma = zeros(1, size(X, 2));

% First, for each feature dimension, compute the mean of the 
% feature and subtract it from the dataset,storing the mean value in mu. 
% Next compute the standard deviation of each feature and divide each feature by it's standard deviation, storing the standard deviation in sigma. 
% Note that X is a matrix where each column is a feature and each row is an example. 
% You need to perform the normalization separately for each feature. 
% Hint: You might find the 'mean' and 'std' functions useful.
mu = mean(X);
sigma = std(X);
X_norm = (X - mu)./sigma;


end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make you understand better what feature normalization does, Below are two images showing the plot when the features of X are normalized against when they are not.&lt;/p&gt;

&lt;h3&gt;RAW DATASET(UN-NORMALIZED)&lt;/h3&gt;
&lt;p style=&quot;clear: both;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\un-normalized.webp&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;FEATURE NORMALIZED&lt;/h3&gt;
&lt;p style=&quot;clear: both;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\normalized.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see,, in the un-normalized plot of our data, we have some of our points directly on the y axis. This is because the range between our dataset is to wide causing some of the smaller values of X to take their places as close as possible to the line. Normalizing our data sets them all in the same range.&lt;/p&gt;

&lt;p&gt;Now we have completed the first step, X an y now holds the values we want them to. These values are what we use to train the model for future house_price predictions. The next step on the list is Compute the cost func. Cost function tries to calculate the value of ‘theta’ that gives the lowest cost/error when it predicts the values that y’s should be. Let’s write the code for it&lt;/p&gt;
&lt;h4&gt;Compute Cost Function&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
% Add intercept(bias) term to X
X = [ones(m, 1) X];
function J = computeCost(X, y, theta)
% J = computeCost(X, y, theta) computes the cost of using theta as the parameter for linear regression to fit the data points in X and y
% Initialize some useful values
m = length(y); % number of training examples
% You need to return the following variables correctly 
J = 0;
% Compute the cost of a particular choice of theta
J = (1/(2*m))*(sum(((X*theta)-y).^2));

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So for the above code, we can see that J is given the value of the cost. The formula above is what is used to compute for cost func in Linear regression. We are constantly multipliying parameters theta and X and subtracting it from our prices y, this helps us to finally calculate the overall cost which we can use in GradientDescent alogrithm to correct. The alogrithm used to compute the costFunction is called “squared error term” , as we are squaring the error of &lt;strong&gt;((X * theta)-y)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now for the Gradient Descent Algorithm. Here, in simple terms we are using the error term computed to learn a better value for our parameters theta. To make you understand better, in gradient descent we are trying to minimize the cost J, for us to do that we need to find the best fit to the data that gives the lowest error i.e, the distance from the points our x’s are located on our data plot is small. Gradient Descent minimizes our cost function on every iteration(loop) of the algorithm, it does this by finding the derivative of J with respect to our parameters and updates J based on this. Finding the derivative simply means, how much does theta affect the cost and minimizing it to attain a global minimum(a point where theta does not change significantly anymore). Now let’s look at the code for Gradient Descent.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning Rate Alpha&lt;/strong&gt; is an hyperparameter in Machine Learning that controls the amount of step taken by gradient descent takes in one iteration of learning parameters theta&lt;/p&gt;
&lt;h4&gt;Compute Gradient Descent&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)
%theta = gradientDescentMulti(x, y, theta, alpha, num_iters) updates theta by taking num_iters gradient steps with learning rate alpha
m = length(y);
% the index of the number of iterations
J_history = zeros(num_iters, 1);
%looping over the total num of iterations
for iter = 1:num_iters
% calculating the error
error = (X * theta) - y;
% updating theta
theta = theta - ((alpha/m) * X'*error);
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the above code, after gradient descent completes , we should have 3 Theta values, becasue we used only three features of X from our dataset. Having more features would mean more theta parameters since theta is the learned parameter that enables us to make predictions on new data having three features in our case.&lt;/p&gt;

&lt;p&gt;That’s all for Linear Regression, we now have our trained model capable of making predictions. In the below and final code we now make a prediction with new unseen data of X of what the price of a house(y) should be or a very close estimate.&lt;/p&gt;

&lt;h4&gt;Predict on New Data&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
% Estimate the price of a 1650 sq-ft, 3 br house
X = [1650,3];
% Feature Normalize the data
featureNormalize(X);
X = ones(:1,X)
% Final prediction price
price = [X].* theta; % Enter your price formula here
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That brings us to the end of this tutorial, we implemented Linear Regression, perhaps the simplest Machine Leraning Algorithm there is, and i would recommend going through it a few times to you know,  improve your intuition on how the code works and also familarize yourself with the code involved. For the code, it’s always possible to copy it down somewhere, refer to it a few times because at first, it wouldn’t stick straightaway but after using it a few times it becomes natural to your senses, I know that because I’ve been in the same sitution. During my first few weeks learning Machine Learning by Andrew, it was overwhelming for me, i got a good understanding of the concepts, intuition but the code was quite strange and hard for me to grasp, but honestly now my eyes passes through the details whenever I’m working with Linear Regression Algo, and I know that would be the same for you.&lt;/p&gt;

&lt;p&gt;In the next article i release , I would give an Introduction to Logistic Regression and you would see how to build a classification model using the Algorithm. Thanks for reading , I hope i’ve been able to uncover and actually simplify Linear Regression Algorithm for you, and with these steps you can go ahead learning the other types we have and you know implementing the ideas and code we looked at. As always, there are nimble steps to take towards finding the right platform, tools, or communities. I would love to read any comments you have about this article or other areas of ML, please feel free to leave a comment below.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">So now that you know a little bit about Machine Learning. It becomes natural for you to understand how you can use it to build models that are capable of making decisions at minimal level. The way we achieve this is the use of Machine Learning Algorithms that were developed several years back by experts in the field.</summary></entry><entry><title type="html">Introduction to Machine Learning Simplified Version</title><link href="http://localhost:4000/introduction-to-machine-learning/" rel="alternate" type="text/html" title="Introduction to Machine Learning Simplified Version" /><published>2020-05-17T00:00:00+01:00</published><updated>2020-05-17T00:00:00+01:00</updated><id>http://localhost:4000/introduction%20to%20machine%20learning</id><content type="html" xml:base="http://localhost:4000/introduction-to-machine-learning/">&lt;p&gt;As someone just starting out in Machine Learning and related fields. I created this blog in other to share my ideas to like-minded individuals out then, I wanted to be able to talk about Machine Leaning in a Simplified way. When I just started out, trying to wrap my head around Artificial Intelligence and Machine Learning, i tried a lot of different sources finding the best way to understand it.&lt;/p&gt;

&lt;p&gt;I was so much interested in Artificial Intelligence in full, wanting to understand how robots worked because in short, it was fascinating to think about. I soon enough found out that to make some very meaningful progress I had to start with Machine-Learnign and i did just that. Enough with the Introduction, I’m going to give a basic and simplified introduction to Machine-Learning (often abbreviated as ML) for complete beginners who want to start their journey in this Field of Study.&lt;/p&gt;

&lt;p&gt;Machine Learning is a sub-field of Artificial Intelligence. It is the concept that defines the different methods in which a Machine (preferably referred to as model) can learn from real world data and have the ability to make accurate predictions. The concept of Machine Learning is a field with many Branches. These branches in total form the different popular methods that Machine Learning is applied in thr real world where it can bring significant improvements to human lives by performing Automation, Analysis or Prediction tasks.&lt;/p&gt;

&lt;p&gt;It becomes a fun thing to think about how we can harness this power and in what ways it can be of benifit to our personal or financial lives. At a very minimal level, those with technical skills therefore think of the ways that models (a program,software capable of making predictions) can be built for use in improving our analysis or prediction power. Below I would give a brief explantion on some of the areas that Machine Learning Technonlogy is being used in real-world &lt;br /&gt;&lt;/p&gt;

&lt;h3 class=&quot;blog-headers&quot;&gt;SOME MACHINE LEARNING TECHNOLOGIES THAT ARE POPULAR TODAY&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ol class=&quot;blog-lists&quot;&gt; --&amp;gt;
	&lt;li&gt;Recommendations Systems: A very popular application of ML models or technology is in the business world as recommender systems. In simple words, a recommendations system is a system deployed for use by businesses to channel the right products to different customers, website vistors, or Users. It uses a simple ML algorithm that can store User data and in future , recommend products the software thinks would suit that Users taste perfectly. The data stored can come in different forms depending on the kind of platform the recommender system should be used. An Example of data a recommender system can store for future use includes (items added to cart, pages visited, time spent on a page,etc). A very Important area to consider when building a recommendations system is where it would be used, because this would generally define the kind of data to be collected and fed to the model.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
	&lt;li&gt;Chatbots: Another ML technology growing at a very fast pace is the Chatbots or Dialog APIs. Chatbots are exactly what their name means, they can have conversations with a human and in a humane way, or well, we are getting there. A chatbot model that has been trained with some ML algorithm has the ability to process sentences and give some response, in most cases, this responses are manually trained by a human i.e A human trainer writes the correct response for different questions,as such, It is to be noted that the most common application of Chatbots are in business websites. They assist Users with a lot of information on how to get things done or to navigate different sections of the site to find what the customer searches for. If you have had any interaction with chatbots, i think you can notice that it isn't a human answering the questions directly. With the current technology, Chatbots are not yet equipped with the best humane touch around, but ofcourse there is reason to believe that this might not be so in a few years. I like the idea of Chatbots, they relieve so much workforce and can just be active anytime of the day fulfilling customers needs and making business mor eproductive.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
	&lt;li&gt;Prediction Software: While not being a main thing You should see around, mostly because a lot of softwares are just an integrating prediction with other types of technology, but for the sake of simplicity, I decided to write about this here afterall it is a ML tech being used. A prediction software or modle is at the very basics of how Machine Learning can be use in real-world. It is probably the easiest to build depending on what area it is to be used. But normally as we have the easiest ML Algorithm capable of making predictions, then yhh, prediction softwares is as easy as ML goes. Prediction softwares are models that have the ability to make predictions and truthfully they can be extremely useful because in practice they cover almost all areas of human lives. One thing that would always make the average human being thrive no amtter the environ ment he finds himself is the ability to make predictions. Through past decades as I'm sure, humans have been able to make predictions, but the really productive thing is a Machine having that ability, this significantly cuts the time in half leaving us to focus our energy and time in collecting data and perhaps devicing better algorithms that can give us more accuracy and faster computational power. And that's exactly what we have been doing these past few years. There are so many researces and advances that it becomes hard to keep up with it all. I think the best we can do is to focus our time in our places of interest, that way everyone is doing a part of evrything that matters.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
	&lt;li&gt;Artificial Intelligence Products: There are a lot of AI products around that do so many fascinating things, they all have their core in ML models. These AI products or APIs are actually built using ML algorithms, trained on diffrent ML Frameworks before they are packaged and deployed on beautiful platforms. To mention a few of them: Video Intelliegnce Tools, Image Classification, Photo Tagging Softwares,and so much more. This AI Products greatly increse human Entertainments, Satisfaction and Effectiveness in different areas.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
 &lt;/ol&gt;

&lt;p&gt;There are so many other applications of Machine Learning that they can not all be mentioned in this article. What many Experts advise is for us to focus on the sub-branches that we find most interesting, focus our time on it and keep learning and making some advancements by challenging ourselves in any way we can.&lt;/p&gt;

&lt;p&gt;We would be looking at the basics of Machine Learning in a simplified way. I should update this article and list some ML Algorithms that help us achieve the differnet advanced technologies we see on the internet today.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">As someone just starting out in Machine Learning and related fields. I created this blog in other to share my ideas to like-minded individuals out then, I wanted to be able to talk about Machine Leaning in a Simplified way. When I just started out, trying to wrap my head around Artificial Intelligence and Machine Learning, i tried a lot of different sources finding the best way to understand it.</summary></entry></feed>