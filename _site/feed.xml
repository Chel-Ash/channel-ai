<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-06-17T00:32:26+01:00</updated><id>http://localhost:4000/feed.xml</id><entry><title type="html">Vectorization - How to Vectorize ML Algorithms with MATLAB</title><link href="http://localhost:4000/vectorization-in-machine-learning-with-matlab/" rel="alternate" type="text/html" title="Vectorization - How to Vectorize ML Algorithms with MATLAB" /><published>2020-06-16T00:00:00+01:00</published><updated>2020-06-16T00:00:00+01:00</updated><id>http://localhost:4000/vectorization%20in%20machine%20learning%20with%20matlab</id><content type="html" xml:base="http://localhost:4000/vectorization-in-machine-learning-with-matlab/">&lt;p&gt;In my previous post, I gave a simplified introduction to Machine Learning for beginners. It therefore brings the need for me to write a post on “Vectorization”. You might be hearing it for the first time or you have possibly come across it sometime. Either one of those, I can tell you that it isn’t a difficult subject, in fact in the field of Machine Learning I found it much easier than a normal iterative code (for &amp;amp; while loop). Now lets begin, by the end of this post I want you to understand what vectorization is, it’s application and how to use it in your ML Implementation.&lt;/p&gt;

&lt;p&gt;The title of this post actually says “Vectorization in ML with MATLAB”, so you can tell I would be teaching you how to vectorize your code with MATLAB as the programming language, but you should know that almost all language codes can be vectorized. Now let’s look at a simplified definition of vectorization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Vectorization&lt;/em&gt;&lt;/strong&gt; is a method of writing codes that makes them run much faster. It applies operators to “multiple” operands without the use of loops, these operands are usually a matrices or vectors.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;A more official defination, cited from &lt;a href=&quot;&quot;&gt;&lt;/a&gt;.&lt;/b&gt;Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at once.. In a vectorized calculation, all elements of the vector (array) can be added in one calculation step.&lt;/p&gt;

&lt;p&gt;Now let’s look into a basic explanation for it. You want to perform calculations on some numbers or in our case, Data, you have to write a piece of code to do the computation for you. In Machine Learning, 80% of the code we are writing is an iterative function, looping over a fixed number of training examples or sort. For example, in Linear Regression, to build a model or predictor we have to compute the cost function and gradient descent over all our training data, and to do this we more than likely need to use loops, that’s where vectorization comes in. Let’s look at what makes vectorization possible in Machine Learning. We would be touching mainly on Matrix and Vectors in this post.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Matrices&lt;/em&gt;&lt;/strong&gt; are in simple form two-dimensional arrays. That is, They are made up of numbers in a 2D shape or size.&lt;/p&gt;

&lt;p&gt;An &lt;a href=&quot;&quot;&gt;Array&lt;/a&gt; on the other hand is a set of numbers arranged in list format, as such, a Matrix can be called an array but not the other way round, simply because a Matrix although being in 2D shape is still a list of numbers in “rows” and “columns”. Let’s take an example so you can understand better.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Example 1:

Array = [2,3,4,6,7,8] %list of num in square brackets

Matrix =[2,3,4;6,7,8] % 2x3 Matrix with 2 rows and 3 columns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the above example,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You can write matrices by separating rows with semicolon(;)&lt;/li&gt;
  &lt;li&gt;By adding a semicolon, we define a new row and also columns&lt;/li&gt;
  &lt;li&gt;Not adding a semicolon makes it an array&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note: We have higher dimensions of Matrices in 3D, 4D etc,, you wouldn’t need to understand it for implementing Machine learning &lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Vectors&lt;/em&gt;&lt;/strong&gt; are one-dimensional arrays. They are similar to matrix with the exception that they have only 1 dimension which is either a row or column.&lt;/p&gt;

&lt;h4&gt;Getting Familiar with Dimensions in Matrix&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;

mat_1 = [4,6;7,8] % A 2x2 matrix (2 rows and 2 columns)

mat_2 = [1,2,3;4,5,6] % A 2x3 matrix (2 rows and 3 columns)

mat_3 = [1,2,5,6;3,4,7,8] % A 2x4 matrix (2 rows and 4 columns)

mat_4 = [1,2;3,4;5,6] % A 3x2 matrix (3 rows and 2 columns)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Check out the visualiztion of the Matrices above in the image below. This would give you a better sense of how they are formed or structure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Blog/Blog-img/matrix_formation.png&quot; class=&quot;img-fluid&quot; alt=&quot;ChannelAI Homepage: Artificial Intelligence&quot; width=&quot;100%&quot; height=&quot;60vh&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vectorization in Machine Learning is done or carried out when we want to perform calculations on Matrix-Matrix or matrix-Vectors. Most of our data in Ml is stored and read in rows and colums. Below are some example of operations with matrix and Vectors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Example 2:

vect_1 = [1;2;3;6;7;8] % A column vector with 6 values

mat_1 = [1,3,5;8,7,6] % A 2x3 Matrix


&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;REASONS FOR VECTORIZING CODE&lt;/h4&gt;
&lt;ul style=&quot;padding: 5;&quot;&gt;
	&lt;li&gt;Appearance: Vectorized mathematical code appears more like the maths we are used to from high-school, making the code easier to understand.&lt;/li&gt;
	&lt;li&gt;Less Error Prone: Without loops, vectorized code is often shorter. Fewer lines of code mean fewer opportunities to introduce programming errors.&lt;/li&gt;
	&lt;li&gt;Performance: Vectorized code often runs much faster than the corresponding code conatining loops&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that we have gone over a few reasons for using vectorized codes, I would like to show you code that outlines the difference in using loops vs vectorization for writing codes. This alone would show you the main idea of vectorization. Although you should know that as model size increases, so does the technique for carrying out vectorization. It gets more advanced but to tell the truth, it’s nothing you can’t handle, as long as you are doing Machine Learning, the concept remains the same as the example below. Let’s write code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Example 4:

This code computes the sine of 1001 values ranging from 0 to 10:
Using Loops:

i = 0;
for t = 0:.01:10
	i = i + 1;
	y(i) = sin(t);
end	

Using Vectorization:

t = 0:.01:10;
y = sin(t);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So there you have it, a few example codes and reasons, more than sufficient why it is advised to vectorize code when Implementing ML. Now that you’ve learnt the basics of Matrix, vectors and code vectorization you can now ahead and use this concept in your work. For reference, all the code for my last post in Linear regression were vectorized, so you can start learning from there how this works in ML and if you want a deeper understanding, check out this course by Vanderblit University on Coursera: &lt;a href=&quot;&quot;&gt;Introduction to Programming with MATLAB&lt;/a&gt;. It covers almost all you need to use Matlab to advanced level. I suggest you enroll if you want to use Matlab as your main programming lang for Machine Learning. Thanks for reading along, I do hope you learnt a thing or two about Vectorization. Even if u feel like you didn’t get much, don’t worry about it, all you need is some practice and you should understand it fully in a short while. If you have any questions related or closely related to our topic, I would very much like to hear it, simply leave a comment below.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">In my previous post, I gave a simplified introduction to Machine Learning for beginners. It therefore brings the need for me to write a post on “Vectorization”. You might be hearing it for the first time or you have possibly come across it sometime. Either one of those, I can tell you that it isn’t a difficult subject, in fact in the field of Machine Learning I found it much easier than a normal iterative code (for &amp;amp; while loop). Now lets begin, by the end of this post I want you to understand what vectorization is, it’s application and how to use it in your ML Implementation.</summary></entry><entry><title type="html">Introduction to Linear Regression - Creating a Simple Learning Predictor</title><link href="http://localhost:4000/linear-regression-simplified/" rel="alternate" type="text/html" title="Introduction to Linear Regression - Creating a Simple Learning Predictor" /><published>2020-05-31T00:00:00+01:00</published><updated>2020-05-31T00:00:00+01:00</updated><id>http://localhost:4000/linear%20regression%20simplified</id><content type="html" xml:base="http://localhost:4000/linear-regression-simplified/">&lt;p&gt;So now that you know a little bit about Machine Learning. It becomes natural for you to understand how you can use it to build models that are capable of making decisions at minimal level. The way we achieve this is the use of Machine Learning Algorithms that were developed several years back by experts in the field.&lt;/p&gt;

&lt;p&gt;The way these algoritm are capable of learning from real-world data to be able to make predictions is mostly because the mathematical computations on which they are built support or are proven to learn or map data to specific labels through probability and with experience.&lt;/p&gt;

&lt;p&gt;In this article, you would be introduced to one of the simplest and popular ML Algorithm called &lt;strong&gt;Linear Regression&lt;/strong&gt;. It is recommended that you read our tutorial on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;Vectorization with Matlab&lt;/a&gt;&lt;/em&gt; if you haven’t already as we would be using vectorization to implement our LR model for faster and easier bug debugging.&lt;/p&gt;

&lt;p&gt;Linear Regression is a ML algorithm that is used for predictions of “continuous /non-classified data”. To better understand it, let’s use a very popular example. Say, you want to predict the prices of particular houses,height of students in a class, weight and so on. This examples define continuous data, that is, they stand alone and are not grouped into classes. This is in contrast to a second learning algorithm called Logistic Regression which we would be looking at in the next post. Before we proceed to the implementation of Linear Regression, i want to give a general idea or intuition about what an ML model is trying to achieve and how it works.&lt;/p&gt;

&lt;p&gt;I learnt Linear Regression from the Stanford University &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;Machine Learning course on Coursera&lt;/a&gt;&lt;/em&gt; taught by Professor Andrew Ng. I feel like i could not have gotten a better understanding if i had learnt it elsewhere, Andrew always wanted to give the students an intuition about any new algorithm we were taking on and i loved it. It made me understand exactly how that algo was different from the previous one even before we started learning the maths behind it. I should say, that’s one of the best course or teaching i have ever received. Now i have this understanding of the different algoritms that even if i were to forget the correct code to implement them i still have a very good grasp of what they are doing and i think that’s very important.&lt;/p&gt;

&lt;p&gt;Now i would give you guys that intuition at the start of every algo you would be learning.&lt;/p&gt;

&lt;p&gt;You have some datasets in continuous values(because we are doing LinearRegrssion) and you want to go about training a model to the point that it achieves a preferred level of accuracy that you consider good enough for the use you want. Yh yh, we want a model that can do that for us but &lt;b&gt;how&lt;/b&gt; does it come to achieve this?. In Machine Learning we have two main types of model learning; supervised and unsupervised. To get more insights on them, read our full article on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;&lt;b&gt;Machine Learning&lt;/b&gt;&lt;/a&gt;&lt;/em&gt;. In Linear Regression we are carrying out the supervised part of learning, think of it as supervised beacuse we are providing some labels or correct values that we want our model to learn from. It goes exactly like this: we have a data set we a number of examples, each of this examples has two values in a row (x and y). The x denotes the value that is fed into the model and y denoting the output of the model. These x’s and y’s are both fed to the model during the training step/phase, therefore the name supervised. 
When we begin to do the math of it, i would explain i details what these terms mean and you should hopefully understand it better.&lt;/p&gt;

&lt;p&gt;We have some specific steps of training that we would take iteratively or repeatedly, the main purpose of this is to reduce the errors generated at each trainng step or loop. Its almost as easy as that. Now we come to the algoritms involoved that helps us achieve that.&lt;/p&gt;

&lt;p&gt;THE THREE MAIN CODE IMPLEMENTATION WHEN TRAINING A LINEAR REGRESSION ALGORITHM:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Prediction function&lt;/li&gt;
  &lt;li&gt;Cost Function&lt;/li&gt;
  &lt;li&gt;Gradient Descent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s look at each of them closely. We know we want an accurate “predictor”, and for that to be, three things has to happen: Our model could start by randomly guessing or well thinking at least it’s guessing correctly but the model would definitely be wrong because initially it hasn’t mapped a function to the data, now we use the cost function to calculate the errors gotten on all our training examples of that step in the loop,that is. the errors when our predictor tried to guess what the output y’s of each x’s were. Finally, the Gradient Descent algo tries to fit our model better by reducing the amount of those errors until it converges to a point that the errors are minimal or can’t be reduced further. Now i would define all the most of the terms used in Linear Regression so you can understand better what each is doing.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Dataset: Dataset is a collection of data, usually data fron real world affairs that can be used to train a model. It can be in either &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;structured&lt;/a&gt;&lt;/em&gt; or &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;unstructured&lt;/a&gt;&lt;/em&gt; form. The stuctured type of data can be divided into &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;supervised&lt;/a&gt;&lt;/em&gt; or &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;unsupervised&lt;/a&gt;&lt;/em&gt; datasets. Datasets sizes ranges from hundreds of trainig examples to as much as millions. Data is usually the first step of model training referred informally as “collecting data”.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Algorithm: A set of mathematical or statistical calculations that is used to compute for numbers, they are proven to give us our answers if implemented in the correct order. Algorithms are found in different fields of study, each constucted to be abstracted will also supporting some higher-level logic for the purpose it’s used.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Training Examples: Usually found in the dataset, training examples in Linear Regression consists of some x’s and y’s which we want our model to learn from considering they are the correct form of matching or mapping that we want. Think of the input x as any subject that can be used to ‘determine’ an effect or some other number. And y being that number that was the result of exactly what &lt;b&gt;x&lt;/b&gt; is. So let’s just say they are dependable of themselves.They are denoted by &lt;b&gt;m&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cost Function: A function in Machine Learning that is always given the task of finding errors after one iteration of learning or after our “predictor” as tried to guess the output of all x’s. Different ML algorithms would come with cost functions that are constructed for exactly how they are used or what concept they support, that in most cases would not work for a different Ml Algorithm. We would call the output y the model is trying to predict &lt;b&gt;y hat&lt;/b&gt;. Consequently, this cost-function is the difference between yhat and y matched be some parameter theta. They are denoted by capital &lt;b&gt;J&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parameters: In Linear Regression, we are trying to predict our y’s given x’s. How we achieve this is that we use parameters called theta to map the function for us. These theta are practically the ones that gives us our errors and by changing them, we can get smaller errors and so on. They are what the model is built upon. In Linear Regression, parameters theta multiplied by our input data x gives us our prediction of ouput y. So you can see how important they are, we use gradient descent to change or reduce the errors calculated by cost function and by changing those errors our parameters theta are defining the predictions a bit more correctly, that is, they are getting better.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gradient Descent: Gradient Deascent is a powerful algorithm that is used in Linear Regression to update theta to a value that gives less errors. It is an iterative function that keeps updating theta in every cycle of the loop until theta converges or gets to the point that it’s reduction if any becomes insignificant.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So now you know the three main steps involved in Linear Regression and hopefully the basic definitions of those terms gave you a better idea of how we train a Predictor or model. Now we can go ahead to implement all these in code. For this tutorial, I would get a dataset of one feature X and output Y from &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;https://www.openml.org/search?type=data&quot;&gt;Open ML&lt;/a&gt;&lt;/em&gt;,a platform where ML engineers and data scientists can collaborate on projects or share datasets. I will be implementing and testing the code written here on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;MATLAB&lt;/a&gt;&lt;/em&gt;, a platform for carrying out mathematical computations and linear algebra. It comes with a free-trial, but to use for an extended period of time, a fee has to be paid. If you want to follow along, you can either use MATLAB or OCTAVE. To set up octave, read our article on &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;&quot;&gt;how to set up octave on windows&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;So I downloaded a dataset from open ML to my PC, I can then login to my MATLAB acct, upload the data, and start building a Linear Regression predictor. Let’s Begin&lt;/p&gt;

&lt;p&gt;AIM OF PREDICTOR&lt;/p&gt;

&lt;p&gt;In this tutorial we would be building a simple model that would use a number of input features x to predict the ‘price’ a building will sell for.&lt;/p&gt;

&lt;p&gt;DATASET&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt;This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.

It contains 19 house features plus the price and the id columns, along with 21613 observations. It's a great dataset for evaluating simple regression models.&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can download this dataset from OpenML &lt;em&gt;&lt;a class=&quot;blog-links&quot; href=&quot;https://www.openml.org/d/42092&quot;&gt;here&lt;/a&gt;&lt;/em&gt;. As stated it is a multi-varaint dataset or simply, it has multiple features in total 19, and 21613 training examples. For this tutorial, we would be using 3 features and 100 training examples.To implement for a uni-variant model, you can follow the whole process but instead load just one feature into the x variable. You would learn about it all soon.&lt;/p&gt;

&lt;p&gt;FEATURES&lt;/p&gt;

&lt;p&gt;The 3 features we would be giving our variable x are &lt;strong&gt;number of bedrooms&lt;/strong&gt;, &lt;strong&gt;sqft of living area&lt;/strong&gt; and &lt;strong&gt;year built&lt;/strong&gt;. There a a lot more features but the reason i chose those 3 is because they seem like the factors that play the largest role of influence on the price a customer would like to pay for a house. Also including similar features like &lt;strong&gt;sqft of basement , sqft of upperlevels&lt;/strong&gt; and so on would end up making the features redundant (repetitive or duplicating). Take a look at the full features in our dataset.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\lr-feature-list.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To set off,we would be using the list as a guide to know the order of the steps it takes to build our model.You can always refer back to this, as a reminder of what steps you should be implementing at what time.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Feature Normalization&lt;/li&gt;
  &lt;li&gt;Plot the Data&lt;/li&gt;
  &lt;li&gt;Compute for the Cost Function&lt;/li&gt;
  &lt;li&gt;Gradient Descent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There is a step included that we have not yet covered, let’s do that now.&lt;/p&gt;

&lt;p&gt;Feature Normalization is a way to neutralize the wide range of values we might have in our dataset. It simply reduces how far apart how data is in their real values in numbers. For example, in  our house_sales dataset we can observe that the difference between the year_built and no_of_bedrooms features is so wide apart and can cause irregularities for our model to learn accurately in lesser time. The way to combat this is simply to normalize our data. In Machine Learning this is referred to as “Feature Normalization”.&lt;/p&gt;

&lt;p&gt;Plotting data is a good way to understand our data, it can be done at different steps when implementing ML algorithm, apart from the purpose of visualization, it also helps us for debugging just by looking at the curves and shapes our data takes.You would learn more about this in future lessons. To plot the data onto a graph, we use a set of built-in functions from MATLAB (same applies in Octave). Whenever i use some new built-in function in our code I would give a brief explanation of what it does, for this reason, anyline starting with a “%” signifies an explanation of the code on the next line. The “%” sign is the official way used to write comments in Matlab.&lt;/p&gt;

&lt;p&gt;Now let’s begin with the first step on the list, which is loading our data into MATLAB Environment normalizing our features so when plotting we can have a better idea of our data.&lt;/p&gt;
&lt;h4&gt;Load the Data into Environment&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
% Load Data
data = load('dataset_');
% Load into X , row 1-100 and columns 4 , 6 &amp;amp; 15
X = data(1:100, [4,6,15])
% Load into y, row 1-100 column 3 (price)
y = data(1:100, 3)
% Denotes the number of training examples , length (100)
m = length(y)
% Call the pre-defined func &quot;featureNormalization&quot;
% It takes one value X and computes three values, (X_normalized, mean of X , range of X)
[X, mu, sigma] = featureNormalize(X)
% Plot the dataset using the normalized X
plot(X,y,'r*')
% Print out first 10 examples from the dataset
fprintf(' x = [%.0f %.0f %.0f], y = %.0f \n', [X(1:10,:) y(1:10,:)]');
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;FeatureNormalization.m&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
Xfunction [X_norm, mu, sigma] = featureNormalize(X) 
%   FEATURENORMALIZE(X) returns a normalized version of X where the mean value of each feature is 0 and the standard deviation is 1. 
% This is often a good preprocessing step to do when working with learning algorithms.

% You need to set these values correctly
X_norm = X;
mu = zeros(1, size(X, 2));
sigma = zeros(1, size(X, 2));

% First, for each feature dimension, compute the mean of the 
% feature and subtract it from the dataset,storing the mean value in mu. 
% Next compute the standard deviation of each feature and divide each feature by it's standard deviation, storing the standard deviation in sigma. 
% Note that X is a matrix where each column is a feature and each row is an example. 
% You need to perform the normalization separately for each feature. 
% Hint: You might find the 'mean' and 'std' functions useful.
mu = mean(X);
sigma = std(X);
X_norm = (X - mu)./sigma;


end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make you understand better what feature normalization does, Below are two images showing the plot when the features of X are normalized against when they are not.&lt;/p&gt;

&lt;h3&gt;RAW DATASET(UN-NORMALIZED)&lt;/h3&gt;
&lt;p style=&quot;clear: both;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\un-normalized.png&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;FEATURE NORMALIZED&lt;/h3&gt;
&lt;p style=&quot;clear: both;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;../assets\images\Blog\Blog-img\normalized.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see,, in the un-normalized plot of our data, we have some of our points directly on the y axis. This is because the range between our dataset is to wide causing some of the smaller values of X to take their places as close as possible to the line. Normalizing our data sets them all in the same range.&lt;/p&gt;

&lt;p&gt;Now we have completed the first step, X an y now holds the values we want them to. These values are what we use to train the model for future house_price predictions. The next step on the list is Compute the cost func. Cost function tries to calculate the value of ‘theta’ that gives the lowest cost/error when it predicts the values that y’s should be. Let’s write the code for it&lt;/p&gt;
&lt;h4&gt;Compute Cost Function&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
% Add intercept(bias) term to X
X = [ones(m, 1) X];
function J = computeCost(X, y, theta)
% J = computeCost(X, y, theta) computes the cost of using theta as the parameter for linear regression to fit the data points in X and y
% Initialize some useful values
m = length(y); % number of training examples
% You need to return the following variables correctly 
J = 0;
% Compute the cost of a particular choice of theta
J = (1/(2*m))*(sum(((X*theta)-y).^2));

end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So for the above code, we can see that J is given the value of the cost. The formula above is what is used to compute for cost func in Linear regression. We are constantly multipliying parameters theta and X and subtracting it from our prices y, this helps us to finally calculate the overall cost which we can use in GradientDescent alogrithm to correct. The alogrithm used to compute the costFunction is called “squared error term” , as we are squaring the error of &lt;strong&gt;((X * theta)-y)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now for the Gradient Descent Algorithm. Here, in simple terms we are using the error term computed to learn a better value for our parameters theta. To make you understand better, in gradient descent we are trying to minimize the cost J, for us to do that we need to find the best fit to the data that gives the lowest error i.e, the distance from the points our x’s are located on our data plot is small. Gradient Descent minimizes our cost function on every iteration(loop) of the algorithm, it does this by finding the derivative of J with respect to our parameters and updates J based on this. Finding the derivative simply means, how much does theta affect the cost and minimizing it to attain a global minimum(a point where theta does not change significantly anymore). Now let’s look at the code for Gradient Descent.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning Rate Alpha&lt;/strong&gt; is an hyperparameter in Machine Learning that controls the amount of step taken by gradient descent takes in one iteration of learning parameters theta&lt;/p&gt;
&lt;h4&gt;Compute Gradient Descent&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)
%theta = gradientDescentMulti(x, y, theta, alpha, num_iters) updates theta by taking num_iters gradient steps with learning rate alpha
m = length(y);
% the index of the number of iterations
J_history = zeros(num_iters, 1);
%looping over the total num of iterations
for iter = 1:num_iters
% calculating the error
error = (X * theta) - y;
% updating theta
theta = theta - ((alpha/m) * X'*error);
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the above code, after gradient descent completes , we should have 3 Theta values, becasue we used only three features of X from our dataset. Having more features would mean more theta parameters since theta is the learned parameter that enables us to make predictions on new data having three features in our case.&lt;/p&gt;

&lt;p&gt;That’s all for Linear Regression, we now have our trained model capable of making predictions. In the below and final code we now make a prediction with new unseen data of X of what the price of a house(y) should be or a very close estimate.&lt;/p&gt;

&lt;h4&gt;Predict on New Data&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;matlab&quot;&gt;
% Estimate the price of a 1650 sq-ft, 3 br house
X = [1650,3];
% Feature Normalize the data
featureNormalize(X);
X = ones(:1,X)
% Final prediction price
price = [X].* theta; % Enter your price formula here
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That brings us to the end of this tutorial, we implemented Linear Regression, perhaps the simplest Machine Leraning Algorithm there is, and i would recommend going through it a few times to you know,  improve your intuition on how the code works and also familarize yourself with the code involved. For the code, it’s always possible to copy it down somewhere, refer to it a few times because at first, it wouldn’t stick straightaway but after using it a few times it becomes natural to your senses, I know that because I’ve been in the same sitution. During my first few weeks learning Machine Learning by Andrew, it was overwhelming for me, i got a good understanding of the concepts, intuition but the code was quite strange and hard for me to grasp, but honestly now my eyes passes through the details whenever I’m working with Linear Regression Algo, and I know that would be the same for you.&lt;/p&gt;

&lt;p&gt;In the next article i release , I would give an Introduction to Logistic Regression and you would see how to build a classification model using the Algorithm. Thanks for reading , I hope i’ve been able to uncover and actually simplify Linear Regression Algorithm for you, and with these steps you can go ahead learning the other types we have and you know implementing the ideas and code we looked at. As always, there are nimble steps to take towards finding the right platform, tools, or communities. I would love to read any comments you have about this article or other areas of ML, please feel free to leave a comment below.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">So now that you know a little bit about Machine Learning. It becomes natural for you to understand how you can use it to build models that are capable of making decisions at minimal level. The way we achieve this is the use of Machine Learning Algorithms that were developed several years back by experts in the field.</summary></entry><entry><title type="html">Introduction to Machine Learning Simplified Version</title><link href="http://localhost:4000/introduction-to-machine-learning/" rel="alternate" type="text/html" title="Introduction to Machine Learning Simplified Version" /><published>2020-05-17T00:00:00+01:00</published><updated>2020-05-17T00:00:00+01:00</updated><id>http://localhost:4000/introduction%20to%20machine%20learning</id><content type="html" xml:base="http://localhost:4000/introduction-to-machine-learning/">&lt;p&gt;As someone just starting out in Machine Learning and related fields. I created this blog in other to share my ideas to like-minded individuals out then, I wanted to be able to talk about Machine Leaning in a Simplified way. When I just started out, trying to wrap my head around Artificial Intelligence and Machine Learning, i tried a lot of different sources finding the best way to understand it.&lt;/p&gt;

&lt;p&gt;I was so much interested in Artificial Intelligence in full, wanting to understand how robots worked because in short, it was fascinating to think about. I soon enough found out that to make some very meaningful progress I had to start with Machine-Learnign and i did just that. Enough with the Introduction, I’m going to give a basic and simplified introduction to Machine-Learning (often abbreviated as ML) for complete beginners who want to start their journey in this Field of Study.&lt;/p&gt;

&lt;p&gt;Machine Learning is a sub-field of Artificial Intelligence. It is the concept that defines the different methods in which a Machine (preferably referred to as model) can learn from real world data and have the ability to make accurate predictions. The concept of Machine Learning is a field with many Branches. These branches in total form the different popular methods that Machine Learning is applied in thr real world where it can bring significant improvements to human lives by performing Automation, Analysis or Prediction tasks.&lt;/p&gt;

&lt;p&gt;It becomes a fun thing to think about how we can harness this power and in what ways it can be of benifit to our personal or financial lives. At a very minimal level, those with technical skills therefore think of the ways that models (a program,software capable of making predictions) can be built for use in improving our analysis or prediction power. Below I would give a brief explantion on some of the areas that Machine Learning Technonlogy is being used in real-world &lt;br /&gt;&lt;/p&gt;

&lt;h3 class=&quot;blog-headers&quot;&gt;SOME MACHINE LEARNING TECHNOLOGIES THAT ARE POPULAR TODAY&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ol class=&quot;blog-lists&quot;&gt; --&amp;gt;
	&lt;li&gt;Recommendations Systems: A very popular application of ML models or technology is in the business world as recommender systems. In simple words, a recommendations system is a system deployed for use by businesses to channel the right products to different customers, website vistors, or Users. It uses a simple ML algorithm that can store User data and in future , recommend products the software thinks would suit that Users taste perfectly. The data stored can come in different forms depending on the kind of platform the recommender system should be used. An Example of data a recommender system can store for future use includes (items added to cart, pages visited, time spent on a page,etc). A very Important area to consider when building a recommendations system is where it would be used, because this would generally define the kind of data to be collected and fed to the model.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
	&lt;li&gt;Chatbots: Another ML technology growing at a very fast pace is the Chatbots or Dialog APIs. Chatbots are exactly what their name means, they can have conversations with a human and in a humane way, or well, we are getting there. A chatbot model that has been trained with some ML algorithm has the ability to process sentences and give some response, in most cases, this responses are manually trained by a human i.e A human trainer writes the correct response for different questions,as such, It is to be noted that the most common application of Chatbots are in business websites. They assist Users with a lot of information on how to get things done or to navigate different sections of the site to find what the customer searches for. If you have had any interaction with chatbots, i think you can notice that it isn't a human answering the questions directly. With the current technology, Chatbots are not yet equipped with the best humane touch around, but ofcourse there is reason to believe that this might not be so in a few years. I like the idea of Chatbots, they relieve so much workforce and can just be active anytime of the day fulfilling customers needs and making business mor eproductive.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
	&lt;li&gt;Prediction Software: While not being a main thing You should see around, mostly because a lot of softwares are just an integrating prediction with other types of technology, but for the sake of simplicity, I decided to write about this here afterall it is a ML tech being used. A prediction software or modle is at the very basics of how Machine Learning can be use in real-world. It is probably the easiest to build depending on what area it is to be used. But normally as we have the easiest ML Algorithm capable of making predictions, then yhh, prediction softwares is as easy as ML goes. Prediction softwares are models that have the ability to make predictions and truthfully they can be extremely useful because in practice they cover almost all areas of human lives. One thing that would always make the average human being thrive no amtter the environ ment he finds himself is the ability to make predictions. Through past decades as I'm sure, humans have been able to make predictions, but the really productive thing is a Machine having that ability, this significantly cuts the time in half leaving us to focus our energy and time in collecting data and perhaps devicing better algorithms that can give us more accuracy and faster computational power. And that's exactly what we have been doing these past few years. There are so many researces and advances that it becomes hard to keep up with it all. I think the best we can do is to focus our time in our places of interest, that way everyone is doing a part of evrything that matters.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
	&lt;li&gt;Artificial Intelligence Products: There are a lot of AI products around that do so many fascinating things, they all have their core in ML models. These AI products or APIs are actually built using ML algorithms, trained on diffrent ML Frameworks before they are packaged and deployed on beautiful platforms. To mention a few of them: Video Intelliegnce Tools, Image Classification, Photo Tagging Softwares,and so much more. This AI Products greatly increse human Entertainments, Satisfaction and Effectiveness in different areas.&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;
 &lt;/ol&gt;

&lt;p&gt;There are so many other applications of Machine Learning that they can not all be mentioned in this article. What many Experts advise is for us to focus on the sub-branches that we find most interesting, focus our time on it and keep learning and making some advancements by challenging ourselves in any way we can.&lt;/p&gt;

&lt;p&gt;We would be looking at the basics of Machine Learning in a simplified way. I should update this article and list some ML Algorithms that help us achieve the differnet advanced technologies we see on the internet today.&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">As someone just starting out in Machine Learning and related fields. I created this blog in other to share my ideas to like-minded individuals out then, I wanted to be able to talk about Machine Leaning in a Simplified way. When I just started out, trying to wrap my head around Artificial Intelligence and Machine Learning, i tried a lot of different sources finding the best way to understand it.</summary></entry><entry><title type="html">Understanding Learning Curves for the Training and Validation sets</title><link href="http://localhost:4000/apples/" rel="alternate" type="text/html" title="Understanding Learning Curves for the Training and Validation sets" /><published>2020-05-16T00:00:00+01:00</published><updated>2020-05-16T00:00:00+01:00</updated><id>http://localhost:4000/apples</id><content type="html" xml:base="http://localhost:4000/apples/">&lt;p&gt;After successfully training a model, we all want it to be as perfect as possible. The way we do this is in Machine Learning is minimizing the error loss on our dataset. But theres a catch, what if we end up overfitting our training set and our learned algorithm fails to generalize on new data. Learn how to balance Learning curves with the Validation set&lt;/p&gt;</content><author><name>Chel</name></author><summary type="html">After successfully training a model, we all want it to be as perfect as possible. The way we do this is in Machine Learning is minimizing the error loss on our dataset. But theres a catch, what if we end up overfitting our training set and our learned algorithm fails to generalize on new data. Learn how to balance Learning curves with the Validation set</summary></entry></feed>