I"3,<p>Are there specific skills important in deep learning?. You shouldn’t be surprised if you ask yourself this question. At a time or another, all budding deep learner ask themselves the same question. Are you a deep learner that flows with the tides that comes along with projects or are you set on building important skills that can make you more effective. In this article, I share 9 skills backed by stactics that guarantees exponential growth in your deep learning career.</p>

<p>Skills are very important. In some cases, more important than others. They help us to go from zero to one in any new field of our interest. This being the case, why do we have learners that never really attain the peaks of their careers since the skills necessary for success is available for all to master?. Could it be that they are learning the <i>wrong</i> skills, learning it the wrong way or more critical, having a skewed perspective to skill gathering.</p>

<p>What then is the correct answer to successful skill gathering for deep learning?. The answer, as you might have guessed lies in the tactful combinations of several skills. Deep learning is a broad field encompassing a number of skills we need to succeed. There is no one-size-fits-all approach. But there are a few key skills you can pick up to ensure that you’ll become a good deep learning practitioner.</p>

<p>The deep learning domain has shifted from being just a degree focused industry to a skill-based industry. Relying on just a degree to become a professional for whahtever sub-domain you choose is now a thing of the past.
Education lands you a job but skills scale up your prospects for growth. In this article, we are going to explore the most important skills required by a deep learner - professional or newcomer.</p>

<h3>Overview</h3>

<ul>
  <li>Difference between a Deep Learner and a Deep Learning Practitioner</li>
  <li>Technical Skills in Deep Learning
    <ul>
      <li>Data Preparation</li>
      <li>Data Visualization</li>
      <li>Functional Programming with Python or R</li>
      <li>Deep Learning Frameworks and Libraries</li>
    </ul>
  </li>
  <li>Soft Skills in Deep Learning
    <ul>
      <li>Problem Solving</li>
      <li>Communication</li>
    </ul>
  </li>
</ul>

<h3>Difference Between a Deep Learner and a Deep Learning Practitioner</h3>

<p>Often I have seen how people use the above 2 terms in a similar context. When people say “I want to be a Deep learner”, In reality and in their heads they mean a Deep Learning Practitioner. So what’s the difference between the two terms? Let’s clarify.</p>

<p>A <b>Deep Learner</b> is more on the theoretical side, refers to a person that is of course enthusiastic about Deep learning as a topic and focuses on learning about it’s concepts, theories and advancement from research papers, blogs and personal research. It is not necessarily a person that puts theory into practise aimed at developing models that solves a problem.</p>

<p>A good and popular example of a deep learner is <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoffery Hinton</a>. You can read about him on wikipedia but basically he is a computer scientist and professor at the University of Toronto. He has brought about tremendous advancement to the fields of Deep learning and computer vision through notable research papers and milestones.</p>

<p>A <b>Deep Learning Practitioner</b> focuses more on practical, technical, analysis, and data side of deep learning. They aim to solve real-world problems by applying Artificial Neural Networks on data to learn functions, build models and deploy for scalable predictions or use-cases. In short, they are the one that</p>

<p>Also a good example in this case woule be Andrew Ng who is less focused on publishing papers(that ofcourse provides groundbreaking ideas which community can build on) and more on building solutions to real-world problems.</p>

<p>In the following sections, we are going to read about the key skills a Deep learning Practitioner should have</p>

<h3>Technical Skills for Deep Learning Practitioners in 2020</h3>

<p>1 &lt;h4 style="color: blue;"&gt;Data Preparation&lt;/h4&gt;</p>

<p>Preparing data may be the most important part of a predictive modeling project and the most time-consuming, although it seems to be the least discussed. The ability to prepare data effectively for use in your projects is as essential as the steps of training the models themselves. Although I know training can feel a lot more fun, afterall that’s where you derive feelings of achievement and effort realised but don’t be fooled to think training is a more important step than preparation. If we’re all being honest, it takes way lesser effort at training stage and if you are using google colab for your work, then that’s just unchallenging to say the least.</p>

<p>Data preparation is usually the first skills needed in any deep learning project. The truth is that, lack of this important skill would reduce your pace in projects completion - every single time. Why? Data comes in different ways and formats. If you choose to rely on stack overflow every time for different and unique data arrangements, they wouldn’t always deliver. You would end up spending valuable time that could have been channeled to advancement in your project.</p>

<p>To give you a sense of the full context of what I mean by data preparation:</p>

<p><i>Data preparation is the process of cleaning and transforming raw data prior to processing and analysis. It is an important step prior to processing and often involves reformatting data, making corrections to data and the combining of data sets to enrich data.</i></p>

<p>Random data are never collected in a format or situations that appeal to the analyst that work with them - Except in some specialised cases of course!</p>

<p>As a useful resource and getting started path for you, below is a list of the 4 areas that will get you started and productive with Data Preparation in Deep Learning:</p>

<ul>
  <li><b>Data Cleaning</b>: Identifying and correcting mistakes or errors in the data. It is hard to find a huge data collection that isn’t messy - containing error and missing values. The easiest tool to use to combat this issue is <a href="">Pandas</a>. What’s better is that you can install/import this python library into almost any environment - locally or online like colab. Pandas is a very easy library to master, for the purpose of data cleaning you can get helpful tutorials on their website. You would learn simple to advanced techniques of how to find missing vales, fill them or remove data rows with erros.</li>
  <li>
    <p><b>Feature Selection</b>: Identifying those input variables that are most relevant to the task. Preparing data for use means to polish it into a state that you can readily use in your modeling project. Feature Selection is step in the data preparation process where you filter and use specific data of your choice.</p>

    <p>Recursive Feature Elimination, or RFE for short, is a popular feature selection algorithm. The scikit-learn Python machine learning library provides an implementation of RFE for machine learning. To get started, visit the scikit-learn docs for RFE where you can learn process that can be repeated for your projects.</p>
  </li>
  <li><b>Normalization</b>: Changing the scale or distribution of variables. One of the most popular techniques for scaling numerical data prior to modeling is normalization. Normalization scales each input variable separately to the range 0-1, which is the range for floating-point values where we have the most precision. This can be done very easily on tensorflow with keras and scikit-learn using the object MinMaxScaler, follow either link for <a href="https://www.tensorflow.org/tutorials/keras/classification#preprocess_the_data">tensorflow</a> or for <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">scikit-learn</a>.</li>
  <li><b>Data Transforms</b>: Transform Data into other Feature types including One-Hot and categorical Encoding . In some of your Deep Learning projects your models may require all input and output variables to exist in a transform different from it’s source. This means that you would need to transform in a manner that is useable for training. Popular DL frameworks has libraries that make this process effortless. 
As before, practicing on tutorials covering this subject would build up the skills for future use. This resource on tensorflow explains the Different <a href="https://www.tensorflow.org/tutorials/structured_data/feature_columns">Feature Types</a> and how to convert/map your values to a specific type. scikit-learn also has a similar tutorial covering <a href="https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html?highlight=feature%20types">Column Transformer with Mixed Types</a>. depending on the platform you use up till now, make a choice</li>
</ul>

<p>2 &lt;h4 style="color: blue;"&gt;Data Visualization&lt;/h4&gt;</p>

<p>Data is visualized in every industry in the 21st century.Data visualization is the act of taking information (data) and placing it into a visual context, such as a map, charts and graph. Data visualizations make big and small data easier for the human brain to understand, and visualization also makes it easier to detect patterns, trends, and outliers in groups of data. Usually, visualization makes it easier to understand the dataset you are working on and to work out the necessary steps it would take you for modeling.</p>

<p>In Python, there are libraries that are widely used for visualization like <a href="https://matplotlib.org/">Matplotlib</a>. To use this tool effectively for various data types and sizes, you would need learn how it works form tutorials you can find on the official page.</p>

<p>Matplotlib is a great tool when you just want to visualize data on a notebook conveniently but for more interactive displays and plots, some more platforms should be used:</p>

<ul>
  <li>
    <p><a href="https://www.tableau.com/">Tableau</a>: By far the most popular, Tableau is a visual analytics platform transforming the way we use data to solve problems
<img src="https://www.tableau.com/themes/custom/tableau_www/logo.png" /></p>
  </li>
  <li>
    <p><a href="https://powerbi.microsoft.com/en-us/">Power BI</a>: Power BI is a business analytics service by Microsoft. It aims to provide interactive visualizations and business intelligence capabilities with an interface simple enough for end users to create their own reports and dashboards. To use it for Deep Learning and Machine Learning, you would need to import a few libraries like PyCaret. To get stated in this, follow this guide by towardsdatascience <a href="https://towardsdatascience.com/machine-learning-in-power-bi-using-pycaret-34307f09394a">Machine Learning in PowerBI using PyCaret</a>
<img src="" /></p>
  </li>
</ul>

<p>3 &lt;h4 style="color: blue;"&gt;Functional Programming with Python&lt;/h4&gt;
In Deep Learning fields, the process of cleaning, preparing, processing, visualizing and others usually needs you to have intermediate to advanced python skills for writing functions that can execute</p>
:ET